<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Personal Model of Trumpery: Linguistic Deception Detection in a Real-World High-Stakes Setting</title>
				<funder ref="#_fJYRJWt">
					<orgName type="full">European Research Council Starting</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sophie</forename><surname>Van</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Der</forename><surname>Zee</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sophie</forename><surname>Van Der Zee</surname></persName>
							<email>vanderzee@ese.eur.nl</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Applied Economics</orgName>
								<orgName type="department" key="dep2">Erasmus School of Economics</orgName>
								<orgName type="institution">Erasmus University Rotterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ronald</forename><surname>Poppe</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Information and Computing Sciences</orgName>
								<orgName type="institution">Utrecht University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alice</forename><surname>Havrileck</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Applied Economics</orgName>
								<orgName type="department" key="dep2">Erasmus School of Economics</orgName>
								<orgName type="institution">Erasmus University Rotterdam</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Economics and Management</orgName>
								<orgName type="institution">École Normale Supérieure Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aurélien</forename><surname>Baillon</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Applied Economics</orgName>
								<orgName type="department" key="dep2">Erasmus School of Economics</orgName>
								<orgName type="institution">Erasmus University Rotterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Erasmus School of Economics</orgName>
								<orgName type="department" key="dep2">Department of Applied Economics</orgName>
								<orgName type="institution">Erasmus University Rotterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Personal Model of Trumpery: Linguistic Deception Detection in a Real-World High-Stakes Setting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ED41F3E3D6C04ADB07E04C59580E4634</idno>
					<idno type="DOI">10.1177/09567976211015941</idno>
					<note type="submission">Received 9/12/19; Revision accepted 3/29/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>deception detection</term>
					<term>linguistic analysis</term>
					<term>LIWC</term>
					<term>Twitter</term>
					<term>tailored model</term>
					<term>open data</term>
					<term>open materials</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Language use differs between truthful and deceptive statements, but not all differences are consistent across people and contexts, complicating the identification of deceit in individuals. By relying on fact-checked tweets, we showed in three studies (Study 1: 469 tweets; Study 2: 484 tweets; Study 3: 24 models) how well personalized linguistic deception detection performs by developing the first deception model tailored to an individual: the 45th U.S. president. First, we found substantial linguistic differences between factually correct and factually incorrect tweets. We developed a quantitative model and achieved 73% overall accuracy. Second, we tested out-of-sample prediction and achieved 74% overall accuracy. Third, we compared our personalized model with linguistic models previously reported in the literature. Our model outperformed existing models by 5 percentage points, demonstrating the added value of personalized linguistic analysis in real-world settings. Our results indicate that factually incorrect tweets by the U.S. president are not random mistakes of the sender.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Language use reveals information about who we are and how we feel <ref type="bibr" target="#b0">(Ahmadian et al., 2017)</ref>. Based on pioneering work in text analysis by Walter <ref type="bibr" target="#b39">Weintraub (1989)</ref>, methods have been developed to automatically count the types of words people use <ref type="bibr" target="#b12">(Fuller et al., 2006;</ref><ref type="bibr" target="#b31">Pennebaker et al., 2015)</ref>. These methods make text analysis an efficient and objective approach to study stable traits such as personality <ref type="bibr" target="#b0">(Ahmadian et al., 2017;</ref><ref type="bibr" target="#b39">Weintraub, 1989)</ref> and more temporary states such as cooperation <ref type="bibr" target="#b32">(Richardson et al., 2014)</ref> and solidarity <ref type="bibr" target="#b34">(Smith et al., 2018)</ref>. Owing to substantial improvements in automated speech recognition, the applicability of such analyses will only further increase <ref type="bibr" target="#b17">(Hirschberg &amp; Manning, 2015)</ref>.</p><p>Language use also differs between truthful and deceptive statements about past events <ref type="bibr" target="#b7">(Bond &amp; Lee, 2005;</ref><ref type="bibr" target="#b13">Fuller et al., 2015;</ref><ref type="bibr" target="#b30">Newman et al., 2003)</ref> and intentions <ref type="bibr" target="#b20">(Kleinberg, van der Toolen, et al., 2018)</ref>. Linguistic analysis showed that liars tend to experience more cognitive load (e.g., fewer different words and exclusive terms), provide fewer details (e.g., fewer sensory-perceptual words), express more negative emotions (e.g., more anger words), distance themselves more than truth tellers (e.g., fewer first-person pronouns), and refer less to cognitive processes (e.g., fewer insight words; <ref type="bibr" target="#b16">Hauch et al., 2015)</ref>. However, observed patterns have been partly contradictory and have limited discriminative power <ref type="bibr" target="#b9">(DePaulo et al., 2003)</ref>. One possible explanation is that the differences between truthful and deceptive language are too small to be consistently observed <ref type="bibr" target="#b36">(Vrij, 2008)</ref>. Alternatively, there might be significant variation between contexts and individuals in language use, which limits the performance of one-size-fits-all models <ref type="bibr" target="#b6">(Bond et al., 2017)</ref>. Whereas several researchers have studied the effect of context on cues to deceit <ref type="bibr" target="#b16">(Hauch et al., 2015;</ref><ref type="bibr" target="#b25">Markowitz &amp; Hancock, 2019)</ref>, the question remains how well the techniques for a whole population can be tailored to a single person. This is important because practitioners must regularly determine whether a specific individual is being deceptive. Answering this question requires a broad set of statements of which the veracity is known, all made by a single individual. To date, this has proven challenging because the fact-checking efforts needed to acquire such a data set are significant.</p><p>In the present article, we put language-based lie detection to the test in a unique real-world setting. We analyzed a multitude of statements made by a single individual, the 45th U.S. president. Several organizations have tasked themselves with fact-checking statements of U.S. presidents, including those made in official speeches, Facebook posts, and tweets <ref type="bibr" target="#b15">(Hasen, 2013)</ref>. Although some messages are posted under the president's name (e.g., Facebook posts) or are delivered by the president (e.g., speeches), the message itself may have been crafted by other individuals, potentially introducing noise to the signal. Of all fact-checked communication channels, the 45th U.S. president's Twitter account seemed to be the one he was most in control of <ref type="bibr" target="#b3">(Barbaro, 2015)</ref>. In addition, tweets are considered official White House communication. A court ruling (Case 1:17-cv-05205-NRB) indeed determined that it was unconstitutional for @realDonaldTrump to block Twitter followers. This official status, combined with systematic fact checking, provides the opportunity for deception detection for a single individual in a highstakes context.</p><p>Previous analyses by independent fact checkers such as The Washington Post, PolitiFact, and The Star concluded that presidential candidates and U.S. presidents regularly make factually incorrect statements <ref type="bibr" target="#b2">(Alterman, 2004;</ref><ref type="bibr" target="#b6">Bond et al., 2017;</ref><ref type="bibr" target="#b27">McGranahan, 2017)</ref>. These statements are often portrayed as deceptive <ref type="bibr" target="#b14">(Glasser, 2018)</ref>. However, an incorrect statement does not necessarily imply a lie. The sender may simply be wrong and have a false belief <ref type="bibr" target="#b5">(Bernstein &amp; Loftus, 2009)</ref>. Being wrong should not affect language use because there is no difference in the perception or intention of the sender. In contrast, when false statements are deliberately presented as truths, one would expect a change in language use, according to the deception hypothesis <ref type="bibr" target="#b7">(Bond &amp; Lee, 2005;</ref><ref type="bibr" target="#b13">Fuller et al., 2015;</ref><ref type="bibr" target="#b16">Hauch et al., 2015)</ref>. The deception hypothesis postulates that lying can cause behavioral change because lying can be cognitively demanding, elicit emotions and stress, and increase attempted behavioral control <ref type="bibr" target="#b9">(DePaulo et al., 2003;</ref><ref type="bibr" target="#b36">Vrij, 2008;</ref><ref type="bibr" target="#b38">Vrij et al., 2017)</ref>. We tested the deception hypothesis by investigating whether differences in language can be used to distinguish between factually correct and factually incorrect statements in tweets of the 45th U.S. president.</p><p>This research comprised three studies. In Study 1, we analyzed differences in language use between factually correct and factually incorrect tweets and developed a personalized deception-detection model. In Study 2, we tested the out-of-sample performance of our model. In Study 3, we compared the performance of our personalized model with that of previously developed language-based deception-detection models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Ethical approval was granted by the internal review board for nonexperimental research of the Erasmus School of Economics, Erasmus University Rotterdam.</p><p>Data collection. To start, we collected a data set (Data Set 1) of all presidential tweets sent by @realDonaldTrump over the 3-month period from February to April 2018. Data for Study 1 were gathered in May 2018. We examined all tweets posted in the 3 most recent, yet completed,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>People use different words when they lie and when they tell the truth. Lying is cognitively demanding and can elicit emotional responses and stress, which is reflected in language use. Several studies have identified linguistic differences between truth and lies, but some findings are contradictory. A possible reason is that language use is personal and so is its modification caused by deception. Linguistic analysis at the individual level is therefore a promising approach to lie detection. To test this possibility, we made use of the existence of a unique data set of factually correct and factually incorrect statements of one single individual in a high-stakes setting: the fact-checked tweets of the 45th U.S. president. We developed a personalized language model, which allowed us to predict whether a statement was correct or potentially deceitful with reasonable accuracy. Our personalized model outperformed existing models from the literature, thereby highlighting the added value of an individualized approach.</p><p>months. The choice of 3 months was a deliberate tradeoff between collecting a sufficient number of tweets and the manual labor involved in data screening. In total, 605 tweets were gathered. The Washington Post provided us with a data set comprising fact-checked communications from this period that we matched to our Twitter data file. As a result, we could identify which tweets were deemed factually incorrect and labeled the remainder as correct. We named the obtained variable veracity. Because fact checking may contain an element of subjectivity, we compared the judged veracity of Data Set 1 with the veracity determined by a second factchecking source, PolitiFact (see the Supplemental Material available online).</p><p>Data screening. Next, the data set was screened to reduce noise. To facilitate word recognition in linguistic analysis, we corrected misspellings <ref type="bibr" target="#b7">(Bond &amp; Lee, 2005;</ref><ref type="bibr" target="#b30">Newman et al., 2003)</ref>. Language use reveals information about the sender only when the sender actually writes the text himself or herself, so we removed tweets contaminated by other individuals. We removed 66 retweets and 52 tweets containing quotes of more than six words to eliminate contamination of our data with tweets from other individuals. We also removed 16 duplicate tweets and two tweets solely containing web links, leaving a final data set of 469 tweets with an average tweet length of 33.75 words. Of these 469 tweets, 142 tweets (30.28%) were classified as factually incorrect and 327 as factually correct (69.72%). Some tweets are part of a tweet series. This is indicated by periods at the end of the first tweet and the beginning of succeeding tweets. Although this series of tweets together conveys one message, we did not combine them to avoid artificial inflation of word count. The Washington Post fact checked the veracity of these tweets separately, allowing for analysis on the tweet rather than message level.</p><p>Linguistic cues. We used the 2015 version of the wellvalidated text-analysis program Linguistic Inquiry and Word Count (LIWC2015; <ref type="bibr" target="#b31">Pennebaker et al., 2015)</ref> to compare language use of correct and incorrect tweets. LIWC assigns words to word categories, ranging from standard linguistic dimensions (e.g., personal pronouns, articles, negations) to psychological processes (e.g., positive and negative emotions, cognitive processing), punctuation categories (e.g., periods, commas, exclamation points), formality measures (e.g., swear words, fillers), and meta categories <ref type="bibr">(e.g., analytic, authentic, tone;</ref><ref type="bibr" target="#b31">Pennebaker et al., 2015)</ref>. Word count is presented as the absolute number of words; all other variables are presented in percentages. Percentages are calculated by counting the number of words belonging to a specific word category and then dividing by word count.</p><p>In Study 3, we applied models reported in the literature to our two data sets. However, some of these models from the literature were created using older versions of LIWC (LIWC2001 and LIWC2007), which contained different sets of word categories from LIWC2015. To allow for testing of those older models and to ensure compatibility between models, we used LIWC2015 for the main set of word categories and added relevant word categories from previous LIWC versions. Our final variable set consisted of 103 variables (101 LIWC word categories from three LIWC versions and two additional Twitter variables). Our set contained 92 out of 93 word categories from LIWC2015. The variable semicolon was removed because there were no semicolons present in our two data sets. In addition, we added four word categories from LIWC2007 (inclusive, inhibition, exclusive, humans) and five word categories from LIWC2001 (sensory and perceptual processes, optimism, total first person, total third person, metaphysical). Last, we added two variables comprising the percentages of the symbols "@" and "#" present in each tweet because these variables play a central role in Twitter communication patterns but are not included in any LIWC variable. The complete list of included LIWC variables appears in Table <ref type="table" target="#tab_1">S1</ref> in the Supplemental Material. When possible, we have linked LIWC categories to the associated psychological processes on the basis of a categorization by <ref type="bibr" target="#b16">Hauch et al. (2015)</ref>. In Figure <ref type="figure" target="#fig_0">1</ref>, the text of two categorized example tweets is displayed. Colors indicate words identified by LIWC as belonging to each of nine example categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Comparing factually correct and incorrect tweets. To test whether language use in factually correct and factually incorrect statements differed, we ran a multivariate analysis of variance (MANOVA). We compared the means of the 101 LIWC variables and two Twitter variables (percentage of @ or # symbols) between the factually correct and the factually incorrect tweets. Using Pillai's trace, this analysis revealed a main effect of veracity, V = .37, F(103, 365) = 2.10, p &lt; .001 (two-sided, as are all the tests reported in this article), η p 2 = .37. Table <ref type="table" target="#tab_1">1</ref> provides the means for factually correct and incorrect statements in Data Set 1, the F statistics, p values adjusted with false-discovery-rate (FDR) correction for multiple comparisons <ref type="bibr" target="#b4">(Benjamini &amp; Hochberg, 1995)</ref>, Bayes factors from a Bayesian t test, and Cohen's ds and their 95% confidence intervals. Table <ref type="table" target="#tab_1">1</ref> includes all variables that were significant at a 5% level with FDR correction (for results for all variables, see Table <ref type="table" target="#tab_1">S1</ref>).</p><p>In total, 36 variables (35.0%) were significant at a 5% level, among which 15 (14.6%) were significant at a 1% level, and 9 (8.7%) were significant at a 0.1% level. These results indicate substantial differences in language use between factually correct and incorrect statements, supporting the deception hypothesis. Correct and incorrect statements differed in terms of cognitive load, certainty, emotions, distance, details, and cognitive processes.</p><p>The act of lying can impact language use in different ways. First, lying can be more cognitively demanding than truth telling, leaving fewer cognitive resources for lie construction <ref type="bibr" target="#b9">(DePaulo et al., 2003)</ref>. As a result, lies are expected to be shorter, less elaborate, and less complex than truths <ref type="bibr" target="#b16">(Hauch et al., 2015)</ref>. Although the incorrect tweets were indeed less elaborate (i.e., fewer six-letter words), they were also longer (i.e., higher word count) and more complex (i.e., more causations and exclusive words) than truths. Second, liars tend to be more verbally and vocally uncertain than truth tellers <ref type="bibr" target="#b9">(DePaulo et al., 2003)</ref>, arguably because of a lack of investment or psychological closeness to their deceptive statement. Whereas the incorrect tweets indeed contained more tentative words, they also contained more certainty words. Third, lying can elicit negative emotions <ref type="bibr" target="#b9">(DePaulo et al., 2003)</ref>. Although incorrect tweets overall contained fewer emotion words than truths, the expressed emotions were more negative. Incorrect tweets contained more anger words and more negative emotion words while containing fewer positive emotion words. Lies also contained more negations, which could indicate a more defensive tone or denial of wrongdoing <ref type="bibr" target="#b16">(Hauch et al., 2015)</ref>. Fourth, liars tend to be less forthcoming and distance themselves more from their story <ref type="bibr" target="#b9">(DePaulo et al., 2003)</ref>, resulting in fewer self-references and more other references <ref type="bibr" target="#b16">(Hauch et al., 2015)</ref>. Incorrect tweets indeed contained fewer first-person pronouns and more third-person pronouns. Fifth, truths and lies typically differ in the type of details. Reality monitoring is a verbal-lie-detection tool that relies on differences between actual experiences (i.e., truths) and internally generated events (i.e., lies). In contrast with imagined events, actual experiences are embedded in memory and typically include a variety of perceptual and sensory details <ref type="bibr" target="#b37">(Vrij, 2015)</ref>. However, we did not find any differences in perceptual details between correct and incorrect tweets and even found an increase rather than a decrease in adverbs. Last, the reality-monitoring approach specifies that liars refer more often to internal, cognitive processes because their story is constructed rather than experienced. We indeed found that incorrect statements contained more cognitive-processing words.</p><p>Model selection. Next, we aimed to explore whether we can predict the factual correctness or incorrectness of a statement. To do so, we proposed to develop a model to predict factually incorrect statements. We used logit regressions with veracity as the dependent variable and determined which subset of the 103 variables to use as independent variables. Too many variables may lead to overfitting and poor out-of-sample prediction power. Several approaches were possible to select variables for the model. When evaluating these approaches, we considered only the 36 variables that were significant at a 5% level according to the MANOVA because regressions of 469 observations on 103 variables led to perfect separation issues with extreme but nonsignificant coefficients. We compared three different model-selection approaches in detail (see the Supplemental Material). Here, we report the results of the forward-stepwise selection, which gave the most parsimonious model. This approach introduces variables one by one until the Akaike information criterion, which penalizes the log likelihood (measuring the goodness of fit) by the number of variables, does not decrease anymore. We implemented this approach starting with the variable with the highest Cohen's d: negate.</p><p>In the remainder of the article, we call the obtained model the personalized model.</p><p>Table 2 reports the marginal effects of the personalized model. For instance, an additional percentage point of negation words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factually Incorrect Tweet</head><p>Only fools or worse are saying that our money losing Post Office makes money with Amazon. THEY LOSE A FORTUNE and this will be changed. Also our fully tax paying retailers are closing stores all over the country...not a level playing field!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Factually Correct Tweet</head><p>Congratulations @ElonMusk and @SpaceX on the successful #FalconHeavy launch. This achievement along with @NASA's commercial and international partners continues to show American ingenuity at its best!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Legend</head><p>Adverb @ Certain Compare Money Negate Period Tentative They  increases the chance of an incorrect statement by 2.5 percentage points, whereas a 1-percentage-point increase in religious words decreases the chance of an incorrect statement by 6.7 percentage points. We classified tweets as predicted incorrect if the model assigned a higher chance than we would expect a priori (i.e., higher than 30.28%), and as predicted correct otherwise. We obtained an overall accuracy of 72.92%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The deception hypothesis predicts that the type of words people use in truthful and deceptive statements differs. To test the occurrence of language differences, we compared factually correct and incorrect tweets by the U.S. president. Results revealed that 35% (36 of the 104) of the tested word types differed between the two categories, supporting the deception hypothesis. Correct and incorrect tweets differed in terms of cognitive load, certainty, negative emotions, distance, details, and cognitive processes. The sender also used fewer @ symbols, a Twitter function to connect an individual to the sender's statement. This finding may best be explained by the verifiability approach. An identifiable person who can be traced is an example of a verifiable detail. Liars use fewer verifiable details than truth tellers <ref type="bibr" target="#b29">(Nahari et al., 2014)</ref>. We also identified differences that were not previously linked to relevant psychological processes, such as punctuation and comparisons. Punctuation can indicate emotions (exclamation marks), suggestions (series of periods, question marks), or the continuation of an idea (periods used in a series of tweets).</p><p>Next, we estimated a logit model to determine how accurately we could identify the veracity of individual tweets on the basis of these language cues. The final model contained 13 variables and correctly classified almost three out of four tweets as either factually correct or incorrect solely on the basis of word use. Because the model was built and tested on the same data, overfitting may have occurred, thereby possibly inflating the results. Out-of-sample testing would provide a more accurate estimate of the general performance of our personalized model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>To test the out-of-sample prediction accuracy of the personalized model developed in Study 1, we collected a second data set (Data Set 2) of presidential tweets. Similar to Data Set 1, Data Set 2 comprised all presidential tweets by @realDonaldTrump covering a 3-month period. Because 3 new months' worth of tweets was not yet available when we collected Data Set 2, we focused on the tweets in the 3 months preceding the period covered in Data Set 1 (November 2017-January 2018). In total, 606 tweets were gathered. We applied identical screening methods as in Study 1, correcting misspellings and removing 85 retweets, six duplications, two tweets containing severe spelling mistakes, and 29 tweets containing quotes with more than six words. The final data set comprised 484 tweets with an average length of 29.37 words. Of these 484 tweets, 111 (22.93%) were classified as factually incorrect by The Washington Post, leaving 373 factually correct tweets (77.07%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Using the personalized model from Study 1, we computed predicted probabilities on out-of-sample tweets. We used the coefficients obtained on the training set (Data Set 1) and applied them to the variables of the test set (Data Set 2) to predict the probability of each tweet being factually incorrect. This probability was compared with a cutoff (e.g., 50%) to classify tweets as predicted correct or predicted incorrect. A hit occurred when a factually incorrect statement was rightly predicted, and a false alarm occurred when a factually correct statement was wrongly predicted to be incorrect. The resulting receiver operating characteristic (ROC) curves, shown in Figure <ref type="figure" target="#fig_1">2</ref>, display hit rates as a function of false-alarm rates when the cutoff varies. The diagonal represents random guessing. The position of the curve above the diagonal shows the improvement over random guessing. It is measured by the area under the curve (AUC); random guessing has an AUC of .5 and a perfect classifier of 1. Figure <ref type="figure" target="#fig_1">2</ref> displays the ROC curves obtained for the test set and for the training set.</p><p>The ROC curve for Data Set 2 is lower than the curve for Data Set 1 but still clearly dominates random guessing. The AUC for the test set is .789, compared with .822 for the training set. As could be expected, it decreased but was still very close to .8. To make the results more concrete, one may want to choose a specific cutoff (i.e., to decide which point of the curve to consider) and compute performance metrics for this cutoff. Table <ref type="table" target="#tab_4">3</ref> reports such metrics. Several approaches to determining the cutoff are possible. The first approach is simply to use .5. In most deceptiondetection research, a cutoff score of .5 would be a sensible choice because half of the statements in such studies tend to be truthful and half deceptive <ref type="bibr" target="#b21">(Levine, 2018)</ref>. For the test set, this gives an overall accuracy of 77.69%, a hit rate of 37.84%, and a false-alarm rate of 10.46%, whereas for the training set, overall accuracy is 76.76%, the hit rate is 49.30%, and the false-alarm rate is 11.31%. This threshold is very conservative, missing many incorrect statements, and less applicable because outside the lab, truth-lie base rates are often not 50-50 <ref type="bibr" target="#b21">(Levine, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>False-Alarm</head><p>Rate Hit Rate 0 0.2 0.4 0.6 0.8 1 0.0 0.2 0.4 0.6 0.8 1.0 (30%, 80%) Data Set 1 = 73% (25%, 68%) Data Set 2 = 74% (30%, 30%) Data Set 1 = 58% Data Set 2 = 61%  <ref type="table" target="#tab_2">2</ref>. The black curve is associated with Data Set 1 (training set) and the gray curve with Data Set 2 (test set). The diagonal represents random guessing, and the black dot represents the prior used as a random guess. The position of the curve above the diagonal shows the improvement over random guessing. Triangles represent when the prior is used as a cutoff in our model. Coordinates of each of these points (i.e., false-alarm and hit rates) are given in parentheses above the accuracy rate for each data set.</p><p>An alternative is to rely on the direction of predictions with respect to our prior. In other words, is a tweet more likely to be factually incorrect than we would have expected? To investigate this question, we used the base rate of factually incorrect statements in the training set (30.28%) as the cutoff. We classified statements for which the model gave a higher probability than the base rate as predicted incorrect. This cutoff in the article is intuitive and easy to interpret. In the test set, it gave a hit rate of 68.47% and a false-alarm rate of 24.66%, yielding an overall accuracy of 73.76%, whereas in the training set, it gave a hit rate of 79.58% and a false-alarm rate of 29.96%, yielding an overall accuracy of 72.92%. For comparison, random guessing using the prior probability of 30.28% for any tweet to be incorrect, would obtain an overall accuracy of 60.68%. Alternatively, the more traditional cutoff of 50% would give an accuracy of 50% for random guessing and higher overall accuracy for our model (76.76% for Data Set 1, 77.69% for Data Set 2). Hence, our approach using a prior probability as the cutoff reduces the difference between random guessing and our model, representing a tougher test of our model.</p><p>We performed various robustness checks (see the Supplemental Material). We (a) excluded word quantity from the analysis, (b) excluded topical variables such as religion and money, (c) developed models to specific topics (work and money), (d) studied the robustness of the out-of-sample performance to various splits between the training set and test set, and (e) conducted a placebo check. Excluding word quantity of topical variables decreased the out-of-sample accuracy by 4 to 5 percentage points, but the obtained models still clearly outperformed random guessing. Models developed for specific topics led to overfitting, with high within-sample AUCs but much lower outof-sample ones. The average out-of-sample AUC over 1,000 splits between the training set and test set was .759, whereas the average AUC, if veracity were random (placebo check), was .5 and did not exceed .59 in 1,000 simulations. In summary, our results were not due to chance, and random inaccuracies could not have been predicted with an AUC of .789.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We investigated how consistent the U.S. president's differences in language use are by predicting the veracity of tweets in an out-of-sample test. We applied the model developed in Study 1 to a new data set to identify classification accuracy on tweets from the same person but different time period. The comparable accuracy within sample (72.92%) and out of sample (73.76%) demonstrates the consistency of the differences in language use over time.</p><p>There are several linguistic deception-detection models previously reported in the literature. Our approach is unique because we developed the first personalized model rather than building a model based on statements by multiple people. Whether unique is also meaningful needs further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>To assess the value of tailoring deception-detection models to a specific individual, we compared the accuracy of our personalized model with models from the literature. Using Google Scholar, we searched for articles containing the terms "deception detection" and "LIWC." We selected all articles that used LIWC to detect deception and specified the LIWC variables in their models. In total, 24 LIWC-based deception-detection models from 14 articles met our criteria. These models can be divided into three types. Theoretical models come from research in which theoretical arguments based on psychological phenomena are made about why some variables should be used in a deception model. For instance, <ref type="bibr" target="#b7">Bond and Lee (2005)</ref>   Note: Accuracy is defined as the percentage of correct responses. Precision is defined as the number of hits divided by the total number of hits and false alarms. F1 is the harmonic mean of precision and hit rate (also called recall). AUC = area under the curve; CI = confidence interval.</p><p>developed to distinguish true from false memories and relies on differences between such memories, such as sensory and perceptual details, temporal details, emotions, and plausibility. Reality monitoring is now one of the most commonly used methods for verbal deception-detection purposes <ref type="bibr" target="#b37">(Vrij, 2015)</ref>. As a result, <ref type="bibr" target="#b7">Bond and Lee (2005)</ref> included the following LIWC categories in their reality-monitoring-based model: "sensory words," "spatial words," "temporal words," "affective words," and "cognitive mechanism words" (in LIWC 2015, these categories correspond to "perceptual processes," "space," "time," "affective processes," and "cognitive processes," respectively). By contrast, data-driven models have been proposed by authors who, as we did in Study 1, let the data speak. Instead of relying on theory to select variables, datadriven models make selections solely on the basis of their performance in distinguishing between tested conditions (i.e., truthful vs. deceptive).</p><p>Finally, theoretical/data-driven models are obtained if theoretical models are restricted to the variables that the authors of the corresponding articles found statistically significant. We added a model with only one predictor, word quantity, as an additional benchmark. There are two reasons that this model makes an interesting benchmark. First, veracity can affect statement length, although results in the literature are mixed. In their metaanalysis, <ref type="bibr">Hauch and colleagues (2015)</ref> found that liars tend to use fewer words but more sentences. A previous meta-analysis by DePaulo and colleagues (2003) tested several related concepts and found that talking time differed between truth tellers and liars, but response length and duration did not. Second, a longer tweet is simply more likely to contain an inaccuracy. Hence, word quantity may be predictive by itself. By comparing the accuracy of more complex models with the accuracy of this one-variable model, we can see the value of analyzing the content of the tweets beyond their mere length. We also included, as another informative benchmark, random guessing using the prior probability of 30.28%.</p><p>For each of the 24 models from the literature, we identified which LIWC variables were included. To allow for a fair comparison between models, instead of relying on coefficients reported in the original articles, we estimated all models on Data Set 1, following the same procedure as for our personalized model in Study 2. We then used the obtained coefficients to compute the accuracy of each model on Data Sets 1 (training) and 2 (test).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The tested models are shown in Table <ref type="table" target="#tab_5">4</ref>. We report the rank, article, type of data, type of model, model origin, LIWC variables included in the model, and overall accuracy and AUC scores for the training and test sets, respectively. When several models were reported within one article, we differentiated between them in the model column. The models are ranked in terms of overall accuracy on the test set (Data Set 2). Overall accuracy scores on the test set range from 50% to 74%, whereas AUC scores range from .443 to .788. The relatively small differences in classification accuracies of the models on Data Sets 1 and 2 again demonstrate the consistent language use in correct and incorrect tweets.</p><p>Our personalized model outperformed all models from the literature by 5 percentage points. This is not surprising on the training set but was not guaranteed on the test set. It shows that we did not overfit the data. Among the best-scoring models from the literature are those that focus on brief chat messages <ref type="bibr" target="#b18">(Ho et al., 2016)</ref> or political statements <ref type="bibr" target="#b8">(Braun et al., 2015)</ref>, both of which consider input that is similar to the political tweets used in the present study. In contrast, the lowest scoring models were developed for other types of data, such as hotel reviews <ref type="bibr" target="#b19">(Kleinberg, Mozes, et al., 2018)</ref> and research articles <ref type="bibr" target="#b24">(Markowitz &amp; Hancock, 2016)</ref>. These results indicate that context matters <ref type="bibr" target="#b25">(Markowitz &amp; Hancock, 2019)</ref>, even though some models developed for other contexts also performed fairly well. Our model included the variable @, which is specific for tweets. Thus, it might have had an unfair advantage over other models that did not include Twitter-related variables. When we ran our model without the @ variable, the classification accuracy on Data Set 1 remained the same (AUC = .816), whereas the accuracy on Data Set 2 decreased by 2 percentage points (AUC = .771). Despite the minor decrease, this model still outperforms models that have not been developed for a specific individual.</p><p>Several variables in our personalized model have not been (e.g., tone, relig) or have rarely been (adverb, compare, money, period) included in other models. This suggests that these variables have not been deemed relevant from a theoretical perspective, nor have they been identified as informative in previous data-driven approaches on other data sets. The superior performance when these terms are present again points to the value of a deception-detection approach tailored to a specific individual in a specific communicative context.</p><p>Results also highlight the importance of word count in our data set. The model comprising word count alone achieved a test set accuracy score of 64%. Moreover, nine models in the top 10 included the word-count variable. We did not see a clear relation between classification accuracy and parsimony (i.e., the number of variables included) of a model. Table 4. (continued)  The results on model origin highlight the value of considering psychological processes. Overall, pure theoretical models seem to perform slightly better than theoretical models that are restricted to their significant variables (theoretical/data-driven models). This gives credit to the psychological processes underlying these models, especially when adapted to a context, even though which set of variables best captures these processes may differ from one study to the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In Study 3, we investigated how our personalized model performed against models previously reported in the literature. Our personalized model appeared as the best-performing out-of-sample model, in terms of both accuracy and AUC. We attribute this to the inclusion of variables that are specific to the individual under consideration and do not necessarily reflect tendencies of the general population. With our data-driven approach, we could identify these variables, which previously have rarely been investigated.</p><p>Together, the way psychological processes are translated in word use seems to differ from one context to the other <ref type="bibr" target="#b25">(Markowitz &amp; Hancock, 2019)</ref> and, as the current results show, from one individual to the other. The best-performing models from the literature were developed from theory for contexts (chats, politics) that are comparable with ours. However, restricting the analysis to variables that were significant in the corresponding articles decreased accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Previous research demonstrated that people's language changes when they lie. Most of this research was conducted using single statements from larger groups of people. Here, we investigated whether we could distinguish between correct and incorrect statements made by a single individual. Fact-checked tweets by the 45th U.S. president uniquely allowed for such a comparison. The MANOVA results from Study 1 showed substantial differences in language use between correct and incorrect tweets, suggesting that the sender was in a different cognitive state when constructing factually incorrect tweets. This finding supports the deception hypothesis.</p><p>Some of these language differences are in line with previous findings in the deception literature. For example, liars experience more negative emotions <ref type="bibr" target="#b30">(Newman et al., 2003;</ref><ref type="bibr">i.e</ref>., increased use of negative emotions and anger words) and higher cognitive load <ref type="bibr" target="#b38">(Vrij et al., 2017;</ref><ref type="bibr"></ref> i.e., increased use of cognitive-processing words and decreased use of six-letter words) than truth tellers. Liars also tend to distance themselves more <ref type="bibr" target="#b35">(Toma &amp; Hancock, 2012;</ref><ref type="bibr"></ref> i.e., increased use of third-person pronouns and decreased use of first-person pronouns). In contrast with previous findings <ref type="bibr" target="#b16">(Hauch et al., 2015)</ref>, our results showed that the factually incorrect tweets sent from the @real DonaldTrump account were longer and more complex than the correct ones. Although tweets are restricted in length, we cannot reject the explanation that longer tweets are simply more likely than shorter tweets to contain erroneous statements.</p><p>Compared with previous findings on language-based deception, the 73% to 74% overall accuracy of our model for both within-sample and out-of-sample prediction is promising. For example, <ref type="bibr">Bond and colleagues (2017)</ref> tested only within-sample accuracy and found classification rates of 63% to 67% based on the communications of U.S. presidential candidates during the 2016 U.S. presidential debates. Sporadically, deception researchers do make out-of-sample predictions, which tend to result in substantial accuracy reductions. For example, <ref type="bibr" target="#b20">Kleinberg, van der Toolen, et al. (2018)</ref> reached a within-sample accuracy of 80% in their study on deceptive intentions, but it dropped to 63% in out-of-sample testing. Such accuracy reductions highlight the importance of out-ofsample testing in deception research. Our high out-ofsample accuracy results show that the language differences between true and false statements are stable within the examined individual, providing support for the usefulness of personalized deception models. Improving random guessing by 12 to 15 percentage points when relying on priors and 27 to 28 percentage points when assuming an equal split between truths and lies, this model could help as a screening tool for anyone interested in political fact checking.</p><p>A limitation of the current study is that we used the fact-checking output of an independent third party as a proxy for the ground truth, potentially introducing noise in our data. The Washington Post labeled statements as incorrect only when they contained incorrect verifiable facts. Opinions, statements that could not be verified, and those about the future are not labeled as factually incorrect, resulting in a conservative estimation of all incorrect tweets.</p><p>A second limitation concerns the sender in two manners. First, we examined only one Twitter account. Although Study 3 shows the strength of personalized deception-detection models, the generalizability of such models remains unclear. Future research could test how well this model performs on other types of communication by the U.S. president or tweets by other individuals. Second, not all tweets sent by @realDonaldTrump may have been typed by the president himself <ref type="bibr" target="#b10">(Draper, 2018)</ref>, introducing noise to the data sets. Journalists have been speculating on how to identify whether the president wrote a tweet himself <ref type="bibr" target="#b11">(Feinberg, 2017)</ref>, but so far, there is no reliable way to distinguish between writers. A more homogeneous data set comprising tweets solely written by the U.S. president would arguably result in stronger effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Linguistic analysis can test whether incorrect statements are predictable and therefore likely to be deceptive. On the one hand, such models can be a screening tool to help journalists in their work as the fourth pillar of democracy. They could also help in identifying potentially incorrect information on social media, where people increasingly turn for daily news <ref type="bibr" target="#b1">(Allcott &amp; Gentzkow, 2017)</ref>. On the other hand, any person having access to people's personal posts and a way to approximate ground truth could develop a model such as the one in this article. Therefore, these results also constitute a warning to all individuals posting a wealth of private, or not so private, information online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Vladimir Sloutsky Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Text of one factually incorrect and one factually correct tweet from Data Set 1 (Study 1). Colors indicate words identified by Linguistic Inquiry and Word Count (LIWC) as belonging to each of nine word categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. Hit rate as a function of false-alarm rate when the cutoff to classify tweets as predicted correct or predicted incorrect varies (Study 2). Predictions were obtained from the model shown in Table2. The black curve is associated with Data Set 1 (training set) and the gray curve with Data Set 2 (test set). The diagonal represents random guessing, and the black dot represents the prior used as a random guess. The position of the curve above the diagonal shows the improvement over random guessing. Triangles represent when the prior is used as a cutoff in our model. Coordinates of each of these points (i.e., false-alarm and hit rates) are given in parentheses above the accuracy rate for each data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>developed a LIWC-based deception-detection model based on reality-monitoring principles. Reality monitoring was</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Statistics for Significant Linguistic Inquiry and Word Count (LIWC) Categories in Data Set 1 (Study 1) Note: The p values reported here are false-discovery-rate corrected. Bayes factor were obtained from a Bayesian t test. Values in brackets after Cohen's ds are 95% confidence intervals. Associated psychological processes are based on categorizations from the study by<ref type="bibr" target="#b16">Hauch et al. (2015)</ref>.</figDesc><table><row><cell>LIWC</cell><cell></cell><cell>Psychological</cell><cell>M if</cell><cell>M if</cell><cell></cell><cell></cell><cell>Bayes</cell><cell></cell></row><row><cell>name</cell><cell>Variable name</cell><cell>process</cell><cell>correct</cell><cell cols="2">incorrect F(1, 603)</cell><cell>p</cell><cell>factor</cell><cell>Cohen's d</cell></row><row><cell>Adverb</cell><cell>Adverbs</cell><cell>Details</cell><cell>3.65</cell><cell>5.36</cell><cell>17.70</cell><cell>.000</cell><cell cols="2">503.44 -0.42 [-0.62, -0.22]</cell></row><row><cell>Affect</cell><cell>Emotions</cell><cell>Emotion</cell><cell>9.76</cell><cell>7.79</cell><cell>7.15</cell><cell>.026</cell><cell>3.43</cell><cell>0.27 [0.07, 0.47]</cell></row><row><cell></cell><cell></cell><cell>(unspecified)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Affiliation</cell><cell>Affiliation</cell><cell></cell><cell>3.68</cell><cell>2.30</cell><cell>9.09</cell><cell>.012</cell><cell>8.65</cell><cell>0.30 [0.10, 0.50]</cell></row><row><cell>Analytic</cell><cell>Analytic thinking</cell><cell></cell><cell>74.71</cell><cell>68.38</cell><cell>5.76</cell><cell>.048</cell><cell>1.77</cell><cell>0.24 [0.04, 0.44]</cell></row><row><cell>Anger</cell><cell>Anger</cell><cell>Emotion</cell><cell>0.39</cell><cell>0.77</cell><cell>9.64</cell><cell>.011</cell><cell cols="2">11.22 -0.31 [-0.51, -0.11]</cell></row><row><cell></cell><cell></cell><cell>(negative)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Apostro</cell><cell>Apostrophes</cell><cell></cell><cell>0.71</cell><cell>1.26</cell><cell>7.04</cell><cell>.026</cell><cell cols="2">3.27 -0.27 [-0.46, -0.07]</cell></row><row><cell>At</cell><cell>@</cell><cell></cell><cell>1.42</cell><cell>0.11</cell><cell>16.67</cell><cell>.001</cell><cell>310.45</cell><cell>0.41 [0.21, 0.61]</cell></row><row><cell>Auxverb</cell><cell>Auxiliary verbs</cell><cell></cell><cell>7.59</cell><cell>9.24</cell><cell>9.45</cell><cell>.012</cell><cell cols="2">10.28 -0.31 [-0.51, -0.11]</cell></row><row><cell>Cause</cell><cell>Causations</cell><cell>Cognitive load</cell><cell>1.07</cell><cell>1.81</cell><cell>12.25</cell><cell>.004</cell><cell cols="2">38.75 -0.35 [-0.55, -0.15]</cell></row><row><cell>Certain</cell><cell>Certainty</cell><cell>Certainty</cell><cell>1.80</cell><cell>2.54</cell><cell>6.19</cell><cell>.039</cell><cell cols="2">2.18 -0.25 [-0.45, -0.05]</cell></row><row><cell>Clout</cell><cell>Clout</cell><cell></cell><cell>70.26</cell><cell>61.17</cell><cell>14.23</cell><cell>.002</cell><cell>98.62</cell><cell>0.38 [0.18, 0.58]</cell></row><row><cell>Cogproc</cell><cell>Cognitive</cell><cell>Cognitive</cell><cell>7.07</cell><cell>10.59</cell><cell>36.86</cell><cell cols="3">.000 &gt; 1,000 -0.61 [-0.81, -0.41]</cell></row><row><cell></cell><cell>processes</cell><cell>processes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Compare</cell><cell>Comparison words</cell><cell></cell><cell>1.40</cell><cell>2.37</cell><cell>12.07</cell><cell>.004</cell><cell cols="2">35.65 -0.35 [-0.55, -0.15]</cell></row><row><cell>Differ</cell><cell>Differentiation</cell><cell></cell><cell>1.62</cell><cell>2.63</cell><cell>15.35</cell><cell>.001</cell><cell cols="2">167.56 -0.39 [-0.59, -0.19]</cell></row><row><cell>Discrep</cell><cell>Discrepancy</cell><cell></cell><cell>1.17</cell><cell>1.73</cell><cell>6.40</cell><cell>.037</cell><cell cols="2">2.40 -0.25 [-0.45, -0.06]</cell></row><row><cell>Drives</cell><cell>Drives</cell><cell></cell><cell>13.24</cell><cell>10.92</cell><cell>8.40</cell><cell>.016</cell><cell>6.24</cell><cell>0.29 [0.09, 0.49]</cell></row><row><cell>Excl</cell><cell>Exclusive</cell><cell>Cognitive load</cell><cell>1.40</cell><cell>2.05</cell><cell>8.18</cell><cell>.016</cell><cell cols="2">5.62 -0.29 [-0.49, -0.09]</cell></row><row><cell>Exclam</cell><cell>Exclamation marks</cell><cell></cell><cell>5.13</cell><cell>2.81</cell><cell>8.28</cell><cell>.016</cell><cell>5.90</cell><cell>0.29 [0.09, 0.49]</cell></row><row><cell>Focuspast</cell><cell>Past orientation</cell><cell></cell><cell>2.48</cell><cell>3.59</cell><cell>10.27</cell><cell>.010</cell><cell cols="2">15.19 -0.32 [-0.52, -0.12]</cell></row><row><cell>Function</cell><cell>Total function</cell><cell></cell><cell>43.37</cell><cell>47.58</cell><cell>14.59</cell><cell>.001</cell><cell cols="2">116.68 -0.38 [-0.58, -0.18]</cell></row><row><cell></cell><cell>words</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metaph</cell><cell>Metaphysical</cell><cell></cell><cell>1.09</cell><cell>0.16</cell><cell>7.70</cell><cell>.020</cell><cell>4.47</cell><cell>0.28 [0.08, 0.48]</cell></row><row><cell>Money</cell><cell>Money</cell><cell></cell><cell>1.26</cell><cell>2.16</cell><cell>8.22</cell><cell>.016</cell><cell cols="2">5.71 -0.29 [-0.49, -0.09]</cell></row><row><cell>Negate</cell><cell>Negations</cell><cell>Emotion</cell><cell>1.05</cell><cell>2.51</cell><cell>47.01</cell><cell cols="3">.000 &gt; 1,000 -0.69 [-0.89, -0.49]</cell></row><row><cell></cell><cell></cell><cell>(negative)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Negemo</cell><cell>Negative emotions</cell><cell>Emotion</cell><cell>2.25</cell><cell>3.66</cell><cell>9.99</cell><cell>.010</cell><cell cols="2">13.26 -0.32 [-0.52, -0.12]</cell></row><row><cell></cell><cell></cell><cell>(negative)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Other</cell><cell>Total third person</cell><cell>Distance</cell><cell>1.41</cell><cell>2.25</cell><cell>9.88</cell><cell>.010</cell><cell cols="2">12.58 -0.32 [-0.51, -0.12]</cell></row><row><cell>OtherP</cell><cell>Other punctuation</cell><cell></cell><cell>3.02</cell><cell>1.17</cell><cell>7.21</cell><cell>.026</cell><cell>3.53</cell><cell>0.27 [0.07, 0.47]</cell></row><row><cell>Period</cell><cell>Periods</cell><cell></cell><cell>6.24</cell><cell>7.99</cell><cell>9.23</cell><cell>.012</cell><cell cols="2">9.24 -0.31 [-0.50, -0.11]</cell></row><row><cell>Posemo</cell><cell>Positive emotions</cell><cell>Emotion</cell><cell>7.43</cell><cell>4.04</cell><cell>23.66</cell><cell cols="2">.000 &gt; 1,000</cell><cell>0.49 [0.29, 0.69]</cell></row><row><cell></cell><cell></cell><cell>(positive)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Relig</cell><cell>Religion</cell><cell></cell><cell>0.67</cell><cell>0.05</cell><cell>9.35</cell><cell>.012</cell><cell>9.81</cell><cell>0.31 [0.11, 0.51]</cell></row><row><cell>Reward</cell><cell>Reward focus</cell><cell></cell><cell>2.92</cell><cell>1.74</cell><cell>8.47</cell><cell>.016</cell><cell>6.45</cell><cell>0.29 [0.09, 0.49]</cell></row><row><cell>Sixltr</cell><cell>Six-letter words</cell><cell>Cognitive load</cell><cell>22.90</cell><cell>20.34</cell><cell>6.32</cell><cell>.037</cell><cell>2.32</cell><cell>0.25 [0.05, 0.45]</cell></row><row><cell>Tentat</cell><cell>Tentative</cell><cell>Certainty</cell><cell>1.20</cell><cell>2.16</cell><cell>18.87</cell><cell>.000</cell><cell cols="2">872.37 -0.44 [-0.64, -0.24]</cell></row><row><cell>They</cell><cell>Third-person</cell><cell></cell><cell>0.73</cell><cell>1.52</cell><cell>16.23</cell><cell>.001</cell><cell cols="2">252.35 -0.40 [-0.6, -0.21]</cell></row><row><cell></cell><cell>plural pronouns</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tone</cell><cell>Emotional tone</cell><cell></cell><cell>67.52</cell><cell>44.73</cell><cell>33.95</cell><cell cols="2">.000 &gt; 1,000</cell><cell>0.59 [0.38, 0.79]</cell></row><row><cell>Verb</cell><cell>Common verbs</cell><cell></cell><cell>13.43</cell><cell>15.70</cell><cell>9.87</cell><cell>.010</cell><cell cols="2">12.56 -0.32 [-0.51, -0.12]</cell></row><row><cell>WC</cell><cell>Word count</cell><cell>Cognitive load</cell><cell>31.22</cell><cell>39.57</cell><cell>37.03</cell><cell cols="3">.000 &gt; 1,000 -0.61 [-0.81, -0.41]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Marginal Effects of Types of Words and Symbols on the Probability of a Tweet Being Incorrect (Study 1)Variables are expressed as percentage of total words, except word quantity, which is expressed as numbers of words. Marginal effects indicate how much veracity varies when a given explanatory variable varies by one unit, other variables being kept constant at their mean value. Results were obtained with a logit regression (log likelihood = -216.75, N = 469).</figDesc><table><row><cell>LIWC variable</cell><cell>Variable name</cell><cell>Marginal effect</cell><cell>SE</cell><cell>z</cell><cell>p</cell></row><row><cell>Negate</cell><cell>Negation</cell><cell>.025</cell><cell>.009</cell><cell>2.925</cell><cell>.003</cell></row><row><cell>WC</cell><cell>Word count</cell><cell>.005</cell><cell>.001</cell><cell>3.346</cell><cell>.001</cell></row><row><cell>Tone</cell><cell>Emotional tone</cell><cell>-.002</cell><cell>.000</cell><cell>-3.565</cell><cell>.000</cell></row><row><cell>At</cell><cell>@</cell><cell>-.050</cell><cell>.019</cell><cell>-2.629</cell><cell>.009</cell></row><row><cell>Relig</cell><cell>Religion</cell><cell>-.067</cell><cell>.032</cell><cell>-2.121</cell><cell>.034</cell></row><row><cell>Compare</cell><cell>Comparison words</cell><cell>.013</cell><cell>.006</cell><cell>2.183</cell><cell>.029</cell></row><row><cell>Period</cell><cell>Periods</cell><cell>.008</cell><cell>.003</cell><cell>2.466</cell><cell>.014</cell></row><row><cell>Tentat</cell><cell>Tentative</cell><cell>.015</cell><cell>.008</cell><cell>1.887</cell><cell>.059</cell></row><row><cell>Money</cell><cell>Money</cell><cell>.011</cell><cell>.005</cell><cell>2.120</cell><cell>.034</cell></row><row><cell>Certain</cell><cell>Certainty</cell><cell>.012</cell><cell>.006</cell><cell>2.013</cell><cell>.044</cell></row><row><cell>They</cell><cell>Third-person plural</cell><cell>.016</cell><cell>.009</cell><cell>1.757</cell><cell>.079</cell></row><row><cell>Adverb</cell><cell>Adverbs</cell><cell>.011</cell><cell>.005</cell><cell>2.181</cell><cell>.029</cell></row><row><cell>Analytic</cell><cell>Analytic thinking</cell><cell>.002</cell><cell>.001</cell><cell>1.809</cell><cell>.070</cell></row><row><cell>Note:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Performance Metrics (Study 2)</figDesc><table><row><cell>Data set</cell><cell></cell><cell>95% CI for</cell><cell></cell><cell>False-</cell><cell></cell><cell></cell><cell></cell><cell>95% CI for</cell></row><row><cell>and cutoff</cell><cell>Accuracy</cell><cell>accuracy</cell><cell>Hit rate</cell><cell>alarm rate</cell><cell>Precision</cell><cell>F1</cell><cell>AUC</cell><cell>AUC</cell></row><row><cell>Data Set 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50.00%</cell><cell>76.76%</cell><cell>[72.5, 80.4]</cell><cell>49.30%</cell><cell>11.31%</cell><cell>65.42%</cell><cell>0.562</cell><cell>.822</cell><cell>[.784, .860]</cell></row><row><cell>30.28%</cell><cell>72.92%</cell><cell>[70.8, 75.1]</cell><cell>79.58%</cell><cell>29.97%</cell><cell>53.55%</cell><cell>0.640</cell><cell>.822</cell><cell>[.784, .860]</cell></row><row><cell>Data Set 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50.00%</cell><cell>77.69%</cell><cell>[75.2, 80.0]</cell><cell>37.84%</cell><cell>10.46%</cell><cell>51.85%</cell><cell>0.438</cell><cell>.788</cell><cell>[.745, .832]</cell></row><row><cell>30.28%</cell><cell>73.76%</cell><cell>[70.7, 76.7]</cell><cell>68.47%</cell><cell>24.66%</cell><cell>45.24%</cell><cell>0.545</cell><cell>.788</cell><cell>[.745, .832]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Model Comparison (Study 3) RankThe column "LIWC variable" describes the model estimated on the training set. Models are ranked on their accuracy on the test set. LIWC =</figDesc><table><row><cell>Test set</cell><cell>Accuracy AUC</cell><cell>74% .788</cell><cell></cell><cell></cell><cell></cell><cell>72% .771</cell><cell></cell><cell></cell><cell></cell><cell>69% .710</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>69% .705</cell><cell></cell><cell></cell><cell>69% .698</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>69% .691</cell><cell></cell><cell></cell><cell>69% .677</cell><cell></cell><cell></cell><cell></cell><cell>69% .670</cell><cell></cell><cell></cell><cell></cell><cell>68% .677</cell><cell>68% .672</cell><cell>(continued)</cell></row><row><cell>Training set</cell><cell>Accuracy AUC</cell><cell>73% .822</cell><cell></cell><cell></cell><cell></cell><cell>73% .816</cell><cell></cell><cell></cell><cell></cell><cell>68% .786</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>68% .758</cell><cell></cell><cell></cell><cell>71% .785</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>70% .767</cell><cell></cell><cell></cell><cell>66% .741</cell><cell></cell><cell></cell><cell></cell><cell>70% .768</cell><cell></cell><cell></cell><cell></cell><cell>68% .754</cell><cell>69% .726</cell></row><row><cell></cell><cell>Origin LIWC variable</cell><cell>Data driven WC + tone + adverb + negate</cell><cell>+ compare + tentat +</cell><cell>money + relig + period +</cell><cell>at + excl</cell><cell>Data driven WC + tone + adverb + negate</cell><cell>+ compare + tentat +</cell><cell>money + relig + period +</cell><cell>excl</cell><cell>Theoretical WC + i + we + you + posemo</cell><cell>+ negemo + insight + cause</cell><cell>+ discrep + tentat + certain</cell><cell>+ inhib + incl + excl +</cell><cell>social + negate</cell><cell>Theoretical/ WC + see + posemo + negate</cell><cell>data + tentat + motion + time</cell><cell>driven</cell><cell>Theoretical WC + i + we + you + shehe</cell><cell>+ they + see + hear + feel</cell><cell>+ posemo + negemo +</cell><cell>motion + negate + excl +</cell><cell>tentat + time</cell><cell>Theoretical WC + i + we + shehe + they</cell><cell>+ negate + negemo</cell><cell></cell><cell>Theoretical WC + dic + sixltr + pronoun +</cell><cell>i + self + other + negate +</cell><cell>article + prep</cell><cell></cell><cell>Theoretical WC + qmark + WPS + i + you</cell><cell>+ shehe + they + negemo</cell><cell>+ negate + excl + cause +</cell><cell>senses</cell><cell>Theoretical/ WC + i + negate + negemo</cell><cell>data</cell><cell>driven</cell><cell>Theoretical i + negate + negemo</cell></row><row><cell></cell><cell>Model name</cell><cell>Personalized</cell><cell></cell><cell></cell><cell></cell><cell>Personalized</cell><cell>without At</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Backward</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Linguistic</cell><cell>dimensions</cell><cell></cell><cell></cell><cell>Full</cell><cell></cell><cell></cell><cell></cell><cell>Full</cell><cell>Emotional</cell></row><row><cell>Communication</cell><cell>Article Context channel</cell><cell>Current article Political Twitter</cell><cell></cell><cell></cell><cell></cell><cell>Current article Political Twitter</cell><cell></cell><cell></cell><cell></cell><cell>Ho et al., 2016 Personal Dyadic chat</cell><cell>experiences messages</cell><cell></cell><cell></cell><cell></cell><cell>Matsumoto &amp; Mock crime Written</cell><cell>Hwang, 2015 statements vs.</cell><cell>interviews</cell><cell>Matsumoto &amp; Mock crime Written</cell><cell>Hwang, 2015 statements vs.</cell><cell>interviews</cell><cell></cell><cell></cell><cell>Braun et al., Political Scripted vs.</cell><cell>2015 interactive</cell><cell>messages</cell><cell>Newman et al., Mock crime Videotaped</cell><cell>2003 Opinions vs. typed vs.</cell><cell>handwritten</cell><cell>statements</cell><cell>Hancock et al., Personal Dyadic chat</cell><cell>2007 experiences messages</cell><cell></cell><cell></cell><cell>Toma &amp; Online dating Profiles</cell><cell>Hancock,</cell><cell>2012</cell><cell>Toma &amp; Online dating Profiles</cell><cell>Hancock,</cell><cell>2012</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>6</cell><cell></cell><cell></cell><cell>7</cell><cell></cell><cell></cell><cell></cell><cell>8</cell><cell></cell><cell></cell><cell></cell><cell>9</cell><cell>10</cell></row></table><note><p>Note:</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We thank the <rs type="institution">Washington Post Fact Checker team</rs> for providing their fact-checked data set of Trump's communications, <rs type="person">Benjamin Tereick</rs> for methodological suggestions, and <rs type="person">Jozien Bensing</rs> and <rs type="person">Annelies Vredeveldt</rs> for providing feedback on the manuscript. For a website discussing the themes of this research, see <ref type="url" target="https://www.apersonalmodeloftrumpery.com/">https://www.apersonalmodeloftrum  pery.com/</ref>.</p></div>
			</div>
			<div type="funding">
<div><head>Funding</head><p>This work was supported by <rs type="funder">European Research Council Starting</rs> Grant <rs type="grantNumber">638408</rs> <rs type="programName">Bayesian Markets</rs>.</p></div>
<div><head>Open Practices</head><p>All data and analysis code have been made publicly available via Figshare and can be accessed at <ref type="url" target="https://doi.org/10.25397/eur.17179514">https://doi.org/  10.25397/eur.17179514</ref>. The design and analysis plans for the studies were not preregistered. This article has received the badges for Open Data and Open Materials. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publi  cations/badges</ref>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fJYRJWt">
					<idno type="grant-number">638408</idno>
					<orgName type="program" subtype="full">Bayesian Markets</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>S. Van Der Zee conceived the idea for this research and gathered the data. S. Van Der Zee and A. Havrileck screened the data and prepared it for analysis. All the authors analyzed the data. The figures were created for the article and for conference presentations by R. Poppe and A. Baillon, and the website for the article was created by A. Havrileck. S. Van Der Zee, R. Poppe, and A. Baillon wrote the original draft of the manuscript, and all the authors provided feedback and approved the final manuscript for submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/09567976211015941">http://  journals.sagepub.com/doi/suppl/10.1177/09567976211015941</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Explaining Donald Trump via communication style: Grandiosity, informality, and dynamism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmadian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Azarshahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Paulhus</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.paid.2016.11.018</idno>
		<ptr target="https://doi.org/10.1016/j.paid.2016.11.018" />
	</analytic>
	<monogr>
		<title level="j">Personality and Individual Differences</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="49" to="53" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social media and fake news in the 2016 election</title>
		<author>
			<persName><forename type="first">H</forename><surname>Allcott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gentzkow</surname></persName>
		</author>
		<idno type="DOI">10.1257/jep.31.2.211</idno>
		<ptr target="https://doi.org/10.1257/jep.31.2.211" />
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Perspectives</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="236" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">When presidents lie: A history of official deception and its consequences</title>
		<author>
			<persName><forename type="first">E</forename><surname>Alterman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Penguin</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pithy, mean and powerful: How Donald Trump mastered Twitter for 2016</title>
		<author>
			<persName><forename type="first">M</forename><surname>Barbaro</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2015/10/06/us/politics/donald-trump-twitter-use-campaign-2016.html" />
	</analytic>
	<monogr>
		<title level="j">The New York Times</title>
		<imprint>
			<date type="published" when="2015-10-05">2015, October 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: A practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2517-6161.1995.tb02031.x</idno>
		<ptr target="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How to tell if a particular memory is true or false</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Loftus</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1745-6924.2009.01140.x</idno>
		<ptr target="https://doi.org/10.1111/j.1745-6924.2009.01140.x" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="370" to="374" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lyin&apos; Ted&apos;, &apos;Crooked Hillary&apos;, and &apos;Deceptive Donald&apos;: Language of lies in the 2016 US presidential debates</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Holman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-A</forename><forename type="middle">L</forename><surname>Eggert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">F</forename><surname>Speller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Mejia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">W</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Ceniceros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rustige</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.3376</idno>
		<ptr target="https://doi.org/10.1002/acp.3376" />
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="668" to="677" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Language of lies in prison: Linguistic classification of prisoners&apos; truthful and deceptive natural language</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.1087</idno>
		<ptr target="https://doi.org/10.1002/acp.1087" />
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="329" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">His lips are moving: Pinocchio effect and other lexical indicators of political deceptions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Van Swol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vang</surname></persName>
		</author>
		<idno type="DOI">10.1080/0163853X.2014.942833</idno>
		<ptr target="https://doi.org/10.1080/0163853X.2014.942833" />
	</analytic>
	<monogr>
		<title level="j">Discourse Processes</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cues to deception</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Depaulo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Muhlenbruck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Charlton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cooper</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909</idno>
		<ptr target="https://doi.org/10.1037/0033-2909" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="74" to="118" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The man behind the president&apos;s tweets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Draper</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2018/04/16/magazine/dan-scavino-the-secretary-of-offense.html" />
	</analytic>
	<monogr>
		<title level="j">The New York Times</title>
		<imprint>
			<date type="published" when="2018-04-16">2018, April 16</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Feinberg</surname></persName>
		</author>
		<ptr target="https://www.wired.com/story/tell-when-someone-else-tweets-from-realdonaldtrump/" />
		<title level="m">How to tell when someone else tweets from @realDonaldTrump</title>
		<imprint>
			<date type="published" when="2017-06-18">2017, June 18</date>
		</imprint>
	</monogr>
	<note type="report_type">Wired</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An analysis of text-based deception detection tools</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Biros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Twitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Burgoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Adkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Americas Conference on Information Systems</title>
		<meeting>the Twelfth Americas Conference on Information Systems</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="3465" to="3472" />
		</imprint>
	</monogr>
	<note>Americas Conference on Information Systems</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Real-world deception and the impact of severity</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Biros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Twitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1080/08874417.2015.11645757</idno>
		<ptr target="https://doi.org/10.1080/08874417.2015.11645757" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Information Systems</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="59" to="67" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On lying and being lied to: A linguistic analysis of deception in computer-mediated communication</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Glasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goorha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Woodworth</surname></persName>
		</author>
		<idno type="DOI">10.1080/01638530701739181</idno>
		<ptr target="https://doi.org/10.1080/01638530701739181" />
	</analytic>
	<monogr>
		<title level="j">Discourse Processes</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2007">2018, August 3. 2007</date>
		</imprint>
	</monogr>
	<note>It&apos;s true: Trump is lying more, and he&apos;s doing it on purpose The New Yorker</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A constitutional right to lie in campaigns and elections</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hasen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Montana Law Review</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="53" to="77" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Are computers effective lie detectors? A metaanalysis of linguistic cues to deception</title>
		<author>
			<persName><forename type="first">V</forename><surname>Hauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Blandon-Gitlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masip</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Sporer</surname></persName>
		</author>
		<idno type="DOI">10.1177/1088868314556539</idno>
		<ptr target="https://doi.org/10.1177/1088868314556539" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="307" to="342" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Advances in natural language processing</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aaa8685</idno>
		<ptr target="https://doi.org/10.1126/science.aaa8685" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">349</biblScope>
			<biblScope unit="page" from="261" to="266" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Computer-mediated deception: Strategies revealed by language-action cues in spontaneous communication</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1080/07421222.2016.1205924</idno>
		<ptr target="https://doi.org/10.1080/07421222.2016.1205924" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="420" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using named entities for computer-automated verbal deception detection</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mozes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arntz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verschuere</surname></persName>
		</author>
		<idno type="DOI">10.1111/1556-4029.13645</idno>
		<ptr target="https://doi.org/10.1111/1556-4029.13645" />
	</analytic>
	<monogr>
		<title level="j">Journal of Forensic Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="714" to="723" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automated verbal credibility assessment of intentions: The model statement technique and predictive modeling</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Van Der Toolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arntz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Verschuere</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.3407</idno>
		<ptr target="https://doi.org/10.1002/acp.3407" />
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="354" to="366" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ecological validity and deception detection research design</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Levine</surname></persName>
		</author>
		<idno type="DOI">10.1080/19312458.2017.1411471</idno>
		<ptr target="https://doi.org/10.1080/19312458.2017.1411471" />
	</analytic>
	<monogr>
		<title level="j">Communication Methods and Measures</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="54" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Linguistic cues to deception and perceived deception in interview dialogues</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Levitan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maredia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human language technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human language technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1941" to="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">When context matters: How false, truthful, and genre-related communication styles are revealed in language</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Markowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Griffin</surname></persName>
		</author>
		<idno type="DOI">10.1080/1068316X.2019.1652751</idno>
		<ptr target="https://doi.org/10.1080/1068316X.2019.1652751" />
	</analytic>
	<monogr>
		<title level="j">Psychology, Crime &amp; Law</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="310" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Linguistic obfuscation in fraudulent science</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Markowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1177/0261927X15614605</idno>
		<ptr target="https://doi.org/10.1177/0261927X15614605" />
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="445" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deception and language: The Contextual Organization of Language and Deception (COLD) framework</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Markowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Palgrave handbook of deceptive communication</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Docan-Morgan</surname></persName>
		</editor>
		<imprint>
			<publisher>Palgrave Macmillan</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="193" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Differences in word usage by truth tellers and liars in written statements and an investigative interview after a mock crime</title>
		<author>
			<persName><forename type="first">D</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.1002/jip.1423</idno>
		<ptr target="https://doi.org/10.1002/jip.1423" />
	</analytic>
	<monogr>
		<title level="j">Journal of Investigative Psychology and Offender Profiling</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="199" to="216" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An anthropology of lying: Trump and the political sociality of moral outrage</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mcgranahan</surname></persName>
		</author>
		<idno type="DOI">10.1111/amet.12475</idno>
		<ptr target="https://doi.org/10.1111/amet.12475" />
	</analytic>
	<monogr>
		<title level="j">American Ethnologist</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="243" to="248" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The lie detector: Explorations in the automatic recognition of deceptive language</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics International Joint Conference on Natural Language Processing Conference</title>
		<meeting>the Association for Computational Linguistics International Joint Conference on Natural Language Processing Conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploiting liars&apos; verbal strategies by examining the verifiability of details</title>
		<author>
			<persName><forename type="first">G</forename><surname>Nahari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2044-8333.2012.02069.x</idno>
		<ptr target="https://doi.org/10.1111/j.2044-8333.2012.02069.x" />
	</analytic>
	<monogr>
		<title level="j">Legal and Criminological Psychology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="227" to="239" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Lying words: Predicting deception from linguistic styles</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Richards</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167203029005010</idno>
		<ptr target="https://doi.org/10.1177/0146167203029005010" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="665" to="675" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The development and psychometric properties of LIWC</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Blackburn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
		<respStmt>
			<orgName>University of Texas</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Language style matching and police interrogation outcomes</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Snook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Conchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bennell</surname></persName>
		</author>
		<idno type="DOI">10.1037/lhb0000077</idno>
		<ptr target="https://doi.org/10.1037/lhb0000077" />
	</analytic>
	<monogr>
		<title level="j">Law and Human Behavior</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="357" to="366" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deception in online dating: Significance and implications for the first offline date</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Sharabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Caughlin</surname></persName>
		</author>
		<idno type="DOI">10.1177/1461444818792425</idno>
		<ptr target="https://doi.org/10.1177/1461444818792425" />
	</analytic>
	<monogr>
		<title level="j">New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="229" to="247" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">After Aylan Kurdi: How tweeting about death, threat, and harm predict increased expressions of solidarity with refugees over time</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mcgarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797617741107</idno>
		<ptr target="https://doi.org/10.1177/0956797617741107" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="623" to="634" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">What lies beneath: The linguistic traces of deception in online dating profiles</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Toma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1460-2466.2011.01619.x</idno>
		<ptr target="https://doi.org/10.1111/j.1460-2466.2011.01619.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="78" to="97" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</author>
		<title level="m">Detecting lies and deceit: Pitfalls and opportunities</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Verbal lie detection tools: Statement validity analysis, reality monitoring and scientific content analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Detecting deception: Current challenges and cognitive approaches</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Granhag</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Verschuere</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley-Blackwell</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A cognitive approach to lie detection: A meta-analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vrij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Blank</surname></persName>
		</author>
		<idno type="DOI">10.1111/lcrp.12088</idno>
		<ptr target="https://doi.org/10.1111/lcrp.12088" />
	</analytic>
	<monogr>
		<title level="j">Legal Criminological Psychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Verbal behavior in everyday life</title>
		<author>
			<persName><forename type="first">W</forename><surname>Weintraub</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
