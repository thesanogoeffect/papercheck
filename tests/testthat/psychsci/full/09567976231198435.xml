<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Different Mechanisms for Supporting Mental Imagery and Perceptual Representations: Modulation Versus Excitation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Pace</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Psychology</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution" key="instit1">University of New South Wales</orgName>
								<orgName type="institution" key="instit2">University of New South Wales</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Psychology</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution" key="instit1">University of New South Wales</orgName>
								<orgName type="institution" key="instit2">University of New South Wales</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Roger</forename><surname>Koenig-Robert</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Psychology</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution" key="instit1">University of New South Wales</orgName>
								<orgName type="institution" key="instit2">University of New South Wales</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joel</forename><surname>Pearson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Psychology</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution" key="instit1">University of New South Wales</orgName>
								<orgName type="institution" key="instit2">University of New South Wales</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Different Mechanisms for Supporting Mental Imagery and Perceptual Representations: Modulation Versus Excitation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C5ABE5B9EFA78025594865F614FD5A0F</idno>
					<idno type="DOI">10.1177/09567976231198435</idno>
					<note type="submission">Received 10/16/22; Revision accepted 8/8/23</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T14:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>mental imagery</term>
					<term>perception</term>
					<term>visual adaptation</term>
					<term>binocular rivalry</term>
					<term>vision</term>
					<term>feedback</term>
					<term>feedforward</term>
					<term>cognition(s)</term>
					<term>cognitive neuroscience</term>
					<term>cognitive processes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent research suggests imagery is functionally equivalent to a weak form of visual perception. Here we report evidence across five independent experiments on adults that perception and imagery are supported by fundamentally different mechanisms: Whereas perceptual representations are largely formed via increases in excitatory activity, imagery representations are largely supported by modulating nonimagined content. We developed two behavioral techniques that allowed us to first put the visual system into a state of adaptation and then probe the additivity of perception and imagery. If imagery drives similar excitatory visual activity to perception, pairing imagery with perceptual adapters should increase the state of adaptation. Whereas pairing weak perception with adapters increased measures of adaptation, pairing imagery reversed their effects. Further experiments demonstrated that these nonadditive effects were due to imagery weakening representations of nonimagined content. Together these data provide empirical evidence that the brain uses categorically different mechanisms to represent imagery and perception.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For most people, the experience of mental imagery is categorically and undeniably different from visual perception. It is degraded, vague, fleeting, or even nonexistent. Despite these striking phenomenological differences, recent research on imagery suggests a tight coupling between imagery and perception. They share similar patterns of brain activity <ref type="bibr" target="#b0">(Albers et al., 2013;</ref><ref type="bibr" target="#b23">Dijkstra et al., 2017;</ref><ref type="bibr" target="#b48">Lee et al., 2012;</ref><ref type="bibr" target="#b57">Naselaris et al., 2015;</ref><ref type="bibr" target="#b59">Pearson, 2019)</ref>, and imagery shows functional effects much like weak perception in priming, learning, conditioning, and adaptation <ref type="bibr" target="#b37">(Ishai &amp; Sagi, 1995;</ref><ref type="bibr" target="#b49">Lewis et al., 2013;</ref><ref type="bibr">Pearson et al., 2008</ref><ref type="bibr" target="#b62">Pearson et al., , 2015;;</ref><ref type="bibr" target="#b76">Tartaglia et al., 2009)</ref>. With the bulk of recent research pointing to the similarities between perception and imagery, the cause of such phenomenological differences remains unknown. A recently proposed hypothesis states that the neurophysiological mechanism behind the striking differences in imagery and perception might be the means by which the two different types of representations are formed: modulation versus driving <ref type="bibr" target="#b44">(Koenig-Robert &amp; Pearson, 2021)</ref>. Perception-related feedforward connections have been classically regarded as driving, meaning that they increase spiking rates in the visual cortex, compared with baseline <ref type="bibr" target="#b42">(Klink et al., 2017;</ref><ref type="bibr" target="#b70">Sherman &amp; Guillery, 1998)</ref>. Imagery is driven by feedback connections, which appear to largely modulate (although not always; see <ref type="bibr" target="#b2">Aru et al., 2020;</ref><ref type="bibr" target="#b4">Bastos et al., 2012)</ref>, often inhibiting rather than driving neuronal activity, especially in lowlevel visual areas <ref type="bibr" target="#b11">(Bullier et al., 2001;</ref><ref type="bibr" target="#b34">Huang et al., 2007</ref><ref type="bibr" target="#b35">Huang et al., , 2017;;</ref><ref type="bibr" target="#b36">Hupé et al., 1998)</ref>. It is thus possible that the neural mechanisms supporting visual imagery representations are mainly explained by the modulation of ongoing activity (i.e., the baseline activity of visual areas) rather than the driving of neural spiking de novo above baseline. Two such different mechanisms, producing different levels of neural activity, might be the source of imagery's different phenomenological experience from that of perception. Here, we aimed to test this hypothesis in a series of behavioral experiments utilizing the sensory bias of imagery on subsequent perception.</p><p>We first devised a novel use of binocular rivalry to compare the mechanisms behind imagery with sensory perception. The historical difficulty with assessing the representational nature of imagery, and comparing it with perception in behavioral experiments, is that the relationship between the visual energy (e.g., contrast) of a prior stimulus and its effect on subsequent processing displays a nonmonotonic function <ref type="bibr" target="#b10">(Brascamp et al., 2007)</ref>. Initial increases in visual energy will increase facilitatory effects on subsequent perception to a point (Fig. <ref type="figure">1A</ref>: Priming). Then, any further increases in energy switch to suppression, as neurons encoding the relevant features start to fatigue, beginning a reduction in facilitatory effects <ref type="bibr" target="#b10">(Brascamp et al., 2007)</ref>. Accordingly, it has been difficult to pinpoint the precise location on the "stimulus energy" curve where the facilitatory bias of imagery begins <ref type="bibr" target="#b10">(Brascamp et al., 2007;</ref><ref type="bibr" target="#b13">Chang et al., 2013;</ref><ref type="bibr" target="#b14">Chang &amp; Pearson, 2018;</ref><ref type="bibr" target="#b37">Ishai &amp; Sagi, 1995;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b75">Tanaka &amp; Sagi, 1998)</ref> as it falls on the nonmonotonic section of the function (orange color; left side of Fig. <ref type="figure">1A</ref>). To overcome this, we utilized strong perception (i.e., high-contrast oriented gratings) to first bring the visual system in a state of adaptation, the monotonic side of the energy function (blue color; right side of Fig. <ref type="figure">1A</ref>). Once in an adapted state, any further neural stimulation from those same visual features will increase adaptation effects, reflected here by suppression of those features from dominance in binocular rivalry (the other orientation will dominate). Thus, using this adapted state as our baseline enabled us to then disambiguate the functional nature of both weak perception and imagery, because any changes to the baseline would be unambiguous in that monotonic section of the curve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants Binocular rivalry experiments. All experiments were approved by the University of New South Wales Human Research Ethics Committee. All methods in this study were performed in accordance with the guidelines and regulations from the Australian National Statement on Ethical Conduct in Human Research (<ref type="url" target="https://www.nhmrc.gov.au/guidelines-publications/e72">https://www.nhmrc   .gov.au/guidelines-publications/e72</ref>). All participants gave informed written or online questionnaire consent to participate in the experiment as part of the requirements for their course. All participants had normal or corrected-tonormal vision. We aimed to test 15 to 20 participants in each experiment in order to replicate previous binocular rivalry research using mental imagery <ref type="bibr" target="#b14">(Chang &amp; Pearson, 2018;</ref><ref type="bibr" target="#b63">Pearson et al., 2011;</ref><ref type="bibr" target="#b71">Sherwood &amp; Pearson, 2010)</ref>. For Experiment 1: Weak Perception, we tested 23 participants (13 female, mean age 21.7 years), with two participants not finishing the experiment because of failure of eye dominance stabilization. For Experiment 2: Imagery, we tested 22 participants (15 female, mean age 21 years), with five participants failing to finish the experiment also because of failure of eye dominance stabilization. Last, for Experiment 3: Imagery + Luminance, we tested 22 participants (13 female, mean age 22.4 years), with five participants left out of final analysis also because of failure of eye dominance stabilization.</p><p>Visual discrimination experiments. For Experiment 4: Adapters + Imagery, we tested 19 participants (10 female, mean age 19.3 years), for Experiment 5: Imagery with No Adapters, we tested 11 participants (4 female, mean age 28.7 years).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual stimuli and apparatus</head><p>Binocular rivalry experiments. We used a Samsung 2494HS widescreen LCD monitor connected to a 14 HP Z230 Tower Workstation. The monitor had a resolution</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Imagine trying to describe a favorite memory to a friend. The mental image is not as defined or strong as the original experience, right? Our research delved into this phenomenon, showing that the process of mental imagery and visual perception are quite different. When we imagine something, we create a sort of picture in our mind, but without the sensory input that comes from the eyes. To help create this mental picture, our brain employs a clever strategy: It dims the activity related to elements we do not imagine, rather like turning down the background noise to focus on a conversation. This paradigm shift in our understanding might explain why mental imagery is seldom experienced as richly as perception and may put an upper limit to its strength. of 1,920 × 1,080 pixels and refresh rate of 60 Hz. Participants' heads were placed on a chin rest 50 cm away from the monitor displayed in a dark room to reduce confounding visual variables.</p><p>A mirror stereoscope was used to present each eye with an oriented grayscale grating. A white square box (visual angle = 2.853 o ) with a white fixation point (visual angle = 0.157 o ) at the center was used in aiding binocular convergence for each eye (see Fig. <ref type="figure">1B</ref>). In each experiment, a static vertical grating was presented to the left eye, and a static horizontal grating was presented to the right eye, with the fixation point in the</p><p>b Response Adapter Blank Rivalry Response Press spacebar to start trial Up for vertical Right for horizontal Down for 50/50 mix Left Eye Right Eye Weak Perception Imagery Imagery + Luminance c d a Priming Suppression Stimulus Energy Modulation Driving Bell Imagery Reversed Suppression Weak Perception Increased Suppression Adapter Only Weak Perception Only Adapter + Weak Perception 50 70 30 10 Congruent Dominance (%) Congruent Dominance * * * * * * * * * * * * 70 50 30 Adapter Only Adapter + Imagery 70 50 30 10 Adapter Only Adapter + Imagery Adapter + Imagery + Luminance * Luminance Disrupts Reversal Effect e * Low High 40 50 60 Vividness Split 1.</p><p>2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>Fig. <ref type="figure">1</ref>. Adaptation paradigm, procedure, and results of the experiments. (a) Suppression paradigm. As a stimulus's energy increases, it can initially increase priming by strengthening its perceptual trace for subsequent perception (blue area, priming). Once its energy begins to cause neuronal fatigue, any increase in energy will increase this fatigue and subsequent suppression of activity, leading to adaptation (blue area, suppression). If this nonmonotonic effect is not taken into account, it is unknown where one stimulus might exert its influence along the priming curve (either before or after the initial increase in priming with increase in energy). Therefore, in our paradigm, imagery was analyzed only in addition to adapters causing suppression, thus preventing ambiguity of the results. (b) Procedure for first three experiments. Participants viewed an adapter followed by a blank gap, then binocular rivalry, indicating what orientation dominated their perception. In the imagery condition, participants imagined the adapter after its presentation during the blank gap. In the imagery + luminance experiment, on half of the trials, the background would ramp up in luminance during the imagery time. In the perceptual experiment, instead of imagery, a weak perceptual prime was presented. (c) Weak perceptual stimuli increased the effect of the perceptual adapters, as predicted by the suppression curve. (d) The opposite effect was found for imagery, reversing the effects of suppression. (e) Experiment 1 imagery result was replicated, additionally showing that the brightness of the background reduced the effect, reflecting a perceptual and not cognitive effect of imagery on rivalry priming. All error bars represent standard error of the mean. An asterisk represents Bonferroni adjusted paired-sample t test p value less than .05; two asterisks, less than .025.</p><p>center of each grating. The gratings (visual angle = 2.5126°, contrast = 15%) were defined by a sinusoidal modulation in stimulus contrast applied to a Gaussianwindowed mean luminance profile (spatial frequency 0.24 cycles per degree), ramping up in luminance at the center. Adapter gratings were presented monocularly, randomized to each eye across trials. The average luminance of the box was 77 cd/m 2 . Average luminance and contrast of the gratings changed for each participant depending on their adaptation results during QUEST (see Method: QUEST). The lowest luminance value used for gratings was 1.24 cd/m 2 , and the highest was 82.8cd/m 2 . The lowest-contrast value used was 3%, and highest was 100%. Background color was the black.</p><p>We requested participants to maintain focus and fixate the fixation point.</p><p>Visual discrimination experiments. We used an Asus ROG PG279Q 27-inch LCD monitor connected to a 14 HP Z230 Tower Workstation. The monitor had a resolution of 2,560 × 1,440 pixels and refresh rate of 60 Hz.</p><p>Participants' heads were placed on a chin rest 50 cm away from the monitor displayed in a dark room to reduce confounding visual variables.All experiments were programmed and run in MATLAB (Mathworks, Natick, MA) using the Psychophysics Toolbox extensions <ref type="bibr" target="#b9">(Brainard, 1997;</ref><ref type="bibr" target="#b41">Kleiner et al., 2007;</ref><ref type="bibr" target="#b64">Pelli, 1997)</ref>.</p><p>Test stimuli were oriented gratings exactly as used in the binocular rivalry experiments with full contrast overlayed on visual noise (see Supplementary Figure <ref type="figure">8</ref> in the Supplemental Material). Static visual noise was a 50 × 50 pixel square box with luminance for each pixel randomly generated every trial, with average values of luminance = 1.99 cd/m 2 ; CIE color space, x = 0.307, y = 0.373. The transparency of the test stimulus overlaying the visual noise was adjusted based on QUEST results per participant as described later (see Estimating Noiseto-Signal Ratios in the Supplemental Material).</p><p>Adapters were oriented gratings exactly the same dimensions as used in the binocular rivalry experiments (see Visual Stimuli and Apparatus), with orientations randomized across trials for each block. Adapters were presented for 5 s at full contrast with average luminance of 77.9 cd/m 2 . To avoid the confound of afterimages, adapters were presented in one of six phases (0°, 30°, 60°, 90°, 120°, or 150°, selected randomly) that randomly alternated every 0.16 s as per previous research <ref type="bibr" target="#b8">(Bradley et al., 1988)</ref>. Longer adapter times were used in this experiment compared with the binocular rivalry studies, as pilot experiments revealed that 3 or 4 s was not long enough to produce adequate suppression of discrimination accuracy. Background color was the black.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Binocular rivalry experiments</head><p>Experiment 1: weak perception. After completing the QUEST: Estimating Adapter Contrasts blocks (see Supplemental Materials: QUEST), participants moved on to the main experiment for weak perception. Participants first viewed a screen with white text stating, "Press spacebar to start trial" (see Fig. <ref type="figure">1B</ref>: Weak Perception). Once selecting spacebar, a 2.5-s blank gap was used before the first adapter was presented.</p><p>This experiment was split into three conditions: adapter only, weak perception only, and adapter + weak perception. In the adapter-only condition, an adapter grating was presented for 1.5 s, followed by a 1-s gap, followed then by binocular rivalry for 750 ms. In the weak-perception only condition, a 1.5-s blank gap was followed by a weakly presented grating for 500 ms, followed by a 500-ms blank gap, followed then by binocular rivalry for 750 ms. Finally, the adapter + weakperception condition consisted of the adapter grating presented for 1.5 s, followed by the weakly presented grating for 500 ms, followed by a 500-ms gap, then the binocular rivalry for 750 ms. Thus, each condition's trials took the same amount of time (3.25 s) and followed the exact same sequential logic. Gratings' orientations were pseudorandomized across trials for each block. At the end of each trial, participants were presented with white text asking, "What did you see? Up for vertical, right for horizontal, down for 50/50 mixed." After indicating what dominated rivalry with the arrow keys, a blank gap appeared for 2.5 s as an interval between trials. Participants on average completed 106 trials per condition, for a total of 318 trials for the experiment. Conditions were presented an equal number of times in a pseudorandomized order for each block.</p><p>Experiment 2: imagery. Participants followed the same sequence as in Experiment 1: Weak Perception, but with different adapter and blank-gap times. A longer gap was used in order to give time for participants to imagine gratings, which necessitated a longer time for adapter grating presentations in order for their effects to persist through to binocular rivalry. Thus, the adapter stimulus was presented for 3 s, followed by a 3-s blank gap (only focal point remains visible in box) and then binocular rivalry for 750 ms. Adapter gratings' orientations were randomized across trials for each block. For the imagery condition, participants were asked to imagine the perceptual adapter as vividly as possible during the blank gap. They were instructed to "use their mind's eye to imagine the adapter exactly as it was presented, as if it never disappeared off screen during the blank." Following rivalry, participants were presented with white text asking, "What did you see? Up for vertical, right for horizontal, down for 50/50 mixed." They were instructed to use arrow keys to indicate which orientation had dominated their perception during rivalry.</p><p>For imagery trials, after dominance was reported, new white text appeared, asking, "How vivid was your imagery? 1 for very low, 2 for moderate low, 3 for moderate high, 4 for very high." Participants were instructed to indicate how clearly and vividly they were able to imagine the adapter stimulus during the gap. At the completion of every trial, a 2.5-s blank gap was used as an interval before the next trial began. For the adapter-only condition, participants performed four blocks of this task with 36 trials in each block, for a total of 144 trials (36 trials per grating contrast). For the adapter + imagery condition, participants performed four blocks of this task with 18 trials in each block, for a total of 72 trials (36 trials per grating contrast). Each block presented only one condition (adapter only or adapter + imagery), but blocks were counterbalanced across the experiment. Participants were encouraged to take short breaks at the end of each block. Before the session, participants completed a supervised training block to ensure they understood the task requirements.</p><p>Experiment 3: imagery + luminance. For Experiment 3, we investigated if the bias in rivalry was reduced due to bright luminance during the imagery period. Thus, the procedure was sequentially identical to Experiment 2 for the adapter-only and adapter + imagery conditions except for stimuli timings. In the adapter-only and adapter + imagery conditions, participants were presented with an adapter stimulus for 4 s, followed by a 5-s blank gap (only focal point and box present), followed by binocular rivalry for 750 ms. However, during the adapter + imagery + luminance condition, the background luminance of the screen increased during the imagery block as per previous experiments <ref type="bibr" target="#b47">(Kwok et al., 2019;</ref><ref type="bibr">Pearson et al., 2008)</ref>. Thus, a longer blank gap (and therefore longer adapter time) was necessary in order to account for the time for luminance to ramp up and down. During the 5-s imagery gap, luminance would smoothly ramp up for 1 s to white (luminance = 48 cd/m 2 ; CIE color space, x = 0.301, y = 0.366), remain white for 3 s, then smoothly ramp back down to black for 1 s. For the adapter-only condition, participants performed four blocks of this task with 18 trials in each block, for a total of 72 trials (36 trials per grating contrast). For the adapter + imagery conditions, participants performed four blocks of this task with 18 trials in each block, for a total of 72 trials (36 trials per luminance condition).</p><p>Adapter-only blocks were presented separate from imagery blocks. Imagery blocks contained an equal but pseudorandomized order of luminance and no-luminance trials. Adapter-only and imagery blocks were counterbalanced across the experiment. Participants were encouraged to take short breaks at the end of each block. Before the session, participants completed a supervised training block to ensure they understood the task requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discrimination experiments</head><p>Experiment 4: adapters + imagery. For experi mental trials, once the space bar was selected, the text was immediately replaced by a fixation point for 2.5 s before the onset of the adapter stimulus. The adapter stimulus was then presented for 5 s, followed by a 3-s blank gap (only focal point remains visible) and then test stimulus for 50 ms (Fig. <ref type="figure">1F</ref>). Test stimuli were presented in pseudorandomized order. The order of the orientation of adapters was pseudorandomized for each block such that an equal number of congruent-or incongruentoriented adapters was presented for each test stimulus.</p><p>For the imagery condition, participants were asked to imagine the perceptual adapter previously presented as vividly as possible during the blank gap. They were instructed to "use their mind's eye to imagine the adapter exactly as it was presented, as if it never disappeared off screen during the blank." Following the test, participants were presented with white text asking, "What did you see? Up for vertical, right for horizontal, down for nothing." They were instructed to use arrow keys to indicate which orientation they had seen within the visual noise. If they could not see an orientation, they were instructed to press the Down arrow. Following discrimination, participants viewed white text asking to select a number referring to their confidence in discrimination: "How confident? 1 for very low, 2 for moderate low, 3 for moderate high, 4 for very high."</p><p>For imagery trials, following confidence reports, new white text appeared, asking, "How vivid was your imagery? 1 for very low, 2 for moderate low, 3 for moderate high, 4 for very high." Participants were instructed to indicate how clearly and vividly they were able to imagine the adapter stimulus during the gap. At the completion of every trial, a 2.5-s blank gap was used as an interval before the next trial began. For each condition, participants performed six blocks of this task with 30 trials in each block, for a total of 180 trials (60 congruent, 60 incongruent, 60 no test stimulus). Adapter-only and imagery blocks were counterbalanced across the experiment. Participants were encouraged to take short breaks at the end of each block. Before the session, participants completed a supervised training block to ensure they understood the task requirements.</p><p>Experiment 5: imagery with no adapters. For this experiment, we aimed to keep the procedure as identical to Experiment 4 as possible but without the presentation of adapters. This was to investigate the possible effects of congruent and incongruent imagery on discrimination accuracy without adapters previously presented. As in previous experiments, participants were first prompted with white text stating, "Press spacebar to begin trial." Once the space bar was pressed, the text was immediately replaced by a fixation point for 3 s with a white circle drawn following the edges of the test gratings (see Supplementary Figure <ref type="figure">9</ref> in the Supplemental Material). This provided an area in which to imagine lines during imagery trials. The circle was presented during imagery and non-imagery blocks in order to account for any potential effects it might have on discrimination accuracy. After 3 s, the test stimulus was presented for 50 ms. Following the test, participants followed the same procedure as before, indicating confidence ratings.</p><p>For the imagery condition, before each block, participants viewed a horizontal and a vertical grating with the same spatial frequency as test gratings in order to familiarize themselves with what to imagine. They were instructed to begin the block only after they became confident that they could imagine the gratings from memory. For each trial, participants were first presented with the fixation point and white circle, followed by a briefly presented text above the circle indicating which orientation to imagine ("Imagine vertical" or "Imagine horizontal"). The order of orientations participants were asked to imagine was pseudorandomized for each block. The text disappeared after 0.5 s, followed by a blank gap (only fixation point and circle remained on screen) for 3 s. Participants were asked to imagine the prompted oriented grating as vividly as possible during this blank gap (once the text had disappeared). Participants then answered vividness and confidence questions as in previous binocular rivalry experiments.</p><p>At the completion of every trial, a 3-s blank gap was used as an interval before the next trial began. For the no-imagery condition, participants performed three blocks with 30 trials in each, for a total of 90 trials (30 vertical, 30 horizontal, 30 no test stimulus trials). For the imagery condition, participants performed six blocks of this task with 30 trials in each block, for a total of 180 trials (60 congruent imagery, 60 incongruent imagery, 60 no test trials). No-adapter and imagery blocks were counterbalanced across the experiment. Participants were encouraged to take short breaks at the end of each block. Before the session, participants completed a supervised training block to ensure they understood the task requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As a proof-of-concept and sanity check, we sought to see if the effects of weak perception increased suppression from prior adaptation, as measured with subsequent rivalry. Once in a state of adaptation/suppression (blue area; right side of Fig. <ref type="figure">1A</ref>), any further stimulation, even by a weak perceptual stimulus, should additively increase adaptation and hence increase suppression in subsequent rivalry (Fig. <ref type="figure">1A</ref>) as documented previously <ref type="bibr" target="#b10">(Brascamp et al., 2007)</ref>. Accordingly, we first presented an adapter stimulus for 1.5 s, followed by a 1-s blank gap. In another condition, we presented a weak perceptual grating for 0.5 s in the blank gap in order to test if it would be additive to adaptation (Fig. <ref type="figure">1B</ref>: Weak Perception). As in previous research <ref type="bibr" target="#b10">(Brascamp et al., 2007;</ref><ref type="bibr" target="#b15">Chang &amp; Pearson, 2020;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b60">Pearson &amp; Brascamp, 2008)</ref>, adapter gratings presented alone suppressed their orientation from dominance in subsequent rivalry (Fig. <ref type="figure">1C</ref>, light-blue middle bar, adapter-only condition), M = 42.9%, SEM ±2.56%, t(20) = -2.77, p = .0354, 95% confidence interval (CI) = [37.56 48.25], k = 3 (Bonferroni adjusted two-tailed t test against chance: 50%), and weak perceptual gratings presented alone produced rivalry priming (Fig. <ref type="figure">1C</ref>, orange leftmost bar, weakperception-only condition), M = 55.67%, SEM ±2%, t(20) = 2.76, p = .0366, 95% CI = [51.38 59.95], k = 3 (Bonferroni adjusted two-tailed t test against chance: 50%). Importantly, as predicted by Figure <ref type="figure">1A</ref>, presenting the weak grating following the high-contrast adapter grating increased the suppression effects on subsequent rivalry compared with the adapter-only condition (Fig. <ref type="figure">1C</ref>, blue rightmost bar, adapter + weak-perception condition), M = -5.3%, SEM ±1.3%, t(20) = 3.995, p = .0021, 95% CI = [2.5, 8], k = 3 (Bonferroni adjusted two-tailed t test). Thus, weak perception, when presented alone, had a facilitative priming effect, hence "mimicking" imagery in previous binocular rivalry experiments <ref type="bibr" target="#b10">(Brascamp et al., 2007;</ref><ref type="bibr" target="#b13">Chang et al., 2013;</ref><ref type="bibr" target="#b39">Keogh &amp; Pearson, 2011</ref><ref type="bibr">, 2021;</ref><ref type="bibr">Pearson et al., 2008)</ref>. However, when presented following a high-contrast adapter, a weak perceptual stimulus produced an additive effect, increasing suppression and presumably the state of adaptation in visual cortex.</p><p>Imagined gratings, much like low-contrast perceptual gratings, produce facilitative priming effects on subsequent rivalry and detection tasks <ref type="bibr" target="#b15">(Chang &amp; Pearson, 2020;</ref><ref type="bibr" target="#b37">Ishai &amp; Sagi, 1995;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b60">Pearson &amp; Brascamp, 2008)</ref>. This has been interpreted as evidence of the representational similarity and mechanistic overlap between imagery and weak perception <ref type="bibr" target="#b59">(Pearson, 2019;</ref><ref type="bibr" target="#b62">Pearson et al., 2015)</ref>, supporting the theory that imagery is much like a weak version of afferent sensory perception. Such a theory would predict that imagery after strong perception would have additive adaptation effects, much like strong and weak perception. Accordingly, in a new experiment (Fig. <ref type="figure">1B</ref>: Imagery), we tested if an adapter followed by an imagined grating would add to the adaptation effect much like a weak perceptual grating did. This experiment followed the same sequential logic as the weak perception experiment, however with different timings in order to allow time for imagery production. We thus presented adapters for 3 s, followed by a 3-s blank gap for imagery. During the blank gap, participants imagined the previously presented adapter grating until they heard a bell, which was followed by the rivalry stimuli. Again, the adapter alone produced strong suppression (Fig. <ref type="figure">1D</ref>, blue left bar, adapter-only condition), M = 37.42%. SEM ±1.66%, t(16) = 7.58, p = 2.1866e-06, 95% CI = [34, 41], k = 2 (Bonferroni adjusted two-tailed paired-sample t test against chance: 50%). However, contrary to an excitatory-only imagery prediction, pairing imagery with the perceptual adapter had the opposite effect of pairing with weak perception, significantly reducing the level of suppression compared with the adapter-only condition (Fig. <ref type="figure">1D</ref>, right orange bar), M = +13.36%, SEM ±3.4%, t(16) = -3.925, p = .0024, 95% CI = [-20.57, -6.14], k = 2 (Bonferroni adjusted two-tailed paired-sample t test against adapter only). This reversal of suppression suggests that imagery cannot be simply explained by driving excitatory activity analogous to weak perception.</p><p>To rule out any high-level decisional bias or attentional effects we ran several control conditions utilizing the documented disruptive effects of uniform background luminance on imagery. Bright uniform background luminance has been shown to reduce the amount of imagery priming but not for other cognitive functions, such as attention <ref type="bibr" target="#b39">(Keogh &amp; Pearson, 2011;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b71">Sherwood &amp; Pearson, 2010)</ref>. In an independent experiment, we added uniform background luminance to the screen during the imagery period (Fig. <ref type="figure">1B</ref>: Imagery + Luminance). Replicating our prior results, adapter alone again produced strong suppression (Fig. <ref type="figure">1E</ref>, leftmost blue bar), M = 28.06%, SEM ±1.81%, t(16) = 12.12, p = 3.5760e-09, 95% CI = [24.22, 31.89], k = 2 (Bonferroni adjusted across-subjects twotailed t test against 50% chance), and adding imagery to the adapter again significantly reduced suppression, replicating the effect (Fig. <ref type="figure">1E</ref>, middle orange bar, adapter + imagery condition), M = +19.61%, SEM ±4.52%, t(16) = -4.34, p = .001, 95% CI = [-29.19, -10], k = 2 (Bonferroni adjusted across-subjects paired-sample two-tailed t test against adapter-only condition). Importantly, when imagery was performed against the uniform irrelevant background luminance (eyes open), there was a significant decline, M = -0.3444, SEM ±0.1088, in vividness ratings (Supplementary Fig. <ref type="figure">11</ref> in the Supplemental Material), t(16) = 3.1656, p = .006, 95% CI = [-0.5751, -0.1138], twotailed t test. The presence of luminance also led to a significantly reduced effect of imagery on reversing suppression (Fig. <ref type="figure">1E</ref>, rightmost light-blue bar), M = -10.11%, SEM ±3.25%, t(16) = 2.32, p = .0338, 95% CI = [0.85, 18.15], across-subjects two-tailed paired-sample t-test adapter + imagery condition difference with adapter + imagery + luminance condition), further suggesting this effect was driven by imagery rather than by response biases.</p><p>Across each imagery experiment, we also included catch trials (see Method) to assess any imagery-induced response bias, consisting of a sham rivalry stimulus (50/50 grating blend) as per previous research <ref type="bibr">(Koenig-Robert &amp; Pearson, 2019;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b65">Rademaker &amp; Pearson, 2012)</ref>. Catch trials were reported veridically (as mixed) at high levels, 97.8%, p = 5.6103e-76, one-sample t test against chance. Together, both experimental controls, the background-luminance and catch trials, suggest that the reversal of suppression by imagery is occurring at a sensory level, ruling out highlevel decisional explanations.</p><p>We then analyzed whether the subjective strength of imagery (vividness) has an effect on the results. In Experiments 2 (Imagery) and 3 (Imagery + Luminance), participants reported imagery vividness in a trial-bytrial basis (see Fig. <ref type="figure">1B</ref>). To account for idiosyncratic self-report differences, we normalized vividness ratings by Z score per participant across the imagery condition, then split into low vividness (below-average vividness) and high vividness (above average) trials. Data from Experiment 2 (Fig. <ref type="figure">1D</ref> inset) showed that low-vividness trials did not significantly reverse the adapter's suppression effects on rivalry dominance (Supplementary Fig. <ref type="figure">1</ref> in the Supplemental Material), M = 8.3%, SEM ±3.68%, t(16) = 2.317, p = .068, 95% CI = [0.72, 16.34], k = 2 (Bonferroni adjusted two-tailed t test), but high-vividness trials did (Supplementary Fig. <ref type="figure">1</ref> in the Supplemental Material), M = 20.08%, SEM ±3.7%, t(16) = 5.422, p = .0001, 95% CI = [12.22, 27.93], k = 2 (Bonferroni adjusted two-tailed t test). This reversal of suppression during high-vividness trials was significantly stronger than any effect of low-vividness trials (Supplementary Fig. <ref type="figure">1</ref> in the Supplemental Material), M = 11.54%, SEM ±5.09%, t(16) = 2.2660, p = .0377, 95% CI = [0.74, 22.34], two-tailed t test.</p><p>Likewise, in Experiment 3 (Fig. <ref type="figure">1E</ref>), high-vividness trials significantly reversed suppression in the adapter + imagery condition (Supplementary Fig. <ref type="figure" target="#fig_2">2</ref> in the Supplemental Material), M = 25.07%, SEM ±5.48%, t(16) = 4.57, p = 6.3600e-04, 95% CI = [13.44, 36.67], k = 4 (Bonferroni adjusted two-tailed t test against adapter-only condition), and the adapter + imagery + luminance (Supplementary Fig. <ref type="figure" target="#fig_2">2</ref> in the Supplemental Material), M = 19.07%, SEM ±5.66%, t(16) = 3.37, p = .0156, 95% CI = [7, 31], k = 4 (Bonferroni adjusted two-tailed t test against adapteronly condition). However, there was a reduced reversal in suppression for low-vividness trials in the adapter + imagery condition (Supplementary Fig. <ref type="figure" target="#fig_2">2</ref> in the Supplemental Material), M = 13.74%, SEM ±4.42%, t(16) = 3.11, p = .0268, 95% CI = <ref type="bibr">[4.38, 23</ref>.1], k = 4 (Bonferroni adjusted two-tailed t test against adapter-only condition), and no significant difference in the adapter + imagery + luminance condition (Supplementary Fig. <ref type="figure" target="#fig_2">2</ref> in the Supplemental Material), M = 1.76%, SEM ±5.24%, t(16) = 0.33, p &gt; 1, 95% CI = [-9.34, 12.87], k = 4 (Bonferroni adjusted two-tailed t test against adapter-only condition).</p><p>Overall, these analyses show that the vividness of imagery was important such that more vivid (subjectively rated as closer to perception) imagery had a stronger reversal of rivalry suppression. This is opposite to what would be predicted by an excitatory perceptionlike account of mental imagery (Koenig-Robert &amp; Pearson, 2021). Thus, these results indicate that the suppressive (i.e., caused by adaptation) effects of perception and the faciliatory effects of imagery are nonadditive over time. Imagery actually reversed the suppressive effects of the adapters rather than increasing them. These data provide compelling novel evidence that imagery cannot be a weakened version of sensory perception and that the two must differ somehow in their neural mechanisms of image representation.</p><p>That weak perception had an additive effect with visual adaptation was unsurprising, given that prior research shows increasing stimulus energy of adapted features increases suppression of those features from rivalry dominance <ref type="bibr" target="#b10">(Brascamp et al., 2007;</ref><ref type="bibr">Pearson et al., 2008)</ref>. However, imagery's reversal of suppression was a novel finding, which prompted us to investigate the underlying mechanism by which imagery elicited this effect. Because binocular rivalry contains both adapted and nonadapted patterns simultaneously (the two rivalry patterns), it was unclear whether imagery's reversal of suppression was via modulation of adapted or nonadapted stimuli or a mixture of both. It is possible that imagery somehow resets the visual system's state of adaptation, reversing neural saturation of adapted features. Alternatively, it is possible that imagery suppressed the nonimagined representation, as has been suggested for auditory activity during visual imagery <ref type="bibr" target="#b1">(Amedi et al., 2005)</ref>. Suppression of nonimagined features may have effectively balanced out the dominance between the adapted stimuli and its rival, resetting dominance toward chance level. Both hypotheses fit with the rivalry data thus far. We therefore devised an experiment to tease apart the possible mechanisms by which imagery reversed adapter suppression in rivalry.</p><p>In addition, we were also interested if these effects generalized beyond the paradigm of binocular rivalry. We hypothesized that imagery might be mainly weakening nonimagined representations (similar to attention; see <ref type="bibr" target="#b32">Gazzaley et al., 2005)</ref> because of its reliance on modulatory (often inhibitory) feedback connections <ref type="bibr" target="#b44">(Koenig-Robert &amp; Pearson, 2021)</ref>. This weakening of the nonimagined content might just have resembled a reversal of adaption caused by our use of rivalry as the dependent measure and its compound nature (e.g., two gratings presented simultaneously). We hypothesize that imagining the adapted grating might be mainly suppressing nonimagined content and hence representations of the nonadapted grating, thus effectively reversing the adapter's suppressive effects on rivalry. To test this, we developed a perceptual discrimination paradigm in which participants discriminated the orientation of a single target grating among static visual noise, subsequent to an adapter and imagery (Fig. <ref type="figure" target="#fig_2">2A</ref>). Having only a single grating as the dependent measure, as opposed to the two in the rivalry display, allowed us to test the effects of imagery on congruent or incongruent representations independently. Any weakening of the nonimagined representations would result in a relative lower performance in the incongruent-imagery condition. If, however, imagery was resetting the state of adaptation, then we should see a release from the adaptation elevation aftereffect in the congruent condition.</p><p>In the adapter-only condition, 19 participants viewed a full-contrast oriented grating for 5 s, then a 3-s blank screen, followed by the target grating for 55 ms (see Method). The orientation of the target could either be congruent (Fig. <ref type="figure" target="#fig_2">2A</ref>: Congruent Trial) or incongruent (90°) to the adapter. The orientation of imagined gratings was always the same as the adapter's orientation. Figure <ref type="figure" target="#fig_2">2B</ref> shows the reductions in target hit rates from the blank baseline condition (no adapter, no imagery). Congruent adapters significantly reduced the hit rate compared with baseline (Fig. <ref type="figure" target="#fig_2">2B</ref>, leftmost blue bar), M = -19.03%, SEM ±3.13%, t(18) = 6.08, p = 1.4167e-05, 95% CI = [13.61, Inf]), k = 4 (Bonferroni adjusted twotailed t test against baseline) and also in comparison to incongruent adapters (Fig. <ref type="figure" target="#fig_2">2B</ref>, middle-right light-blue bar), M = -12.28%, SEM ±2.31%, t(18) = 5.325, p = 6.9237e-05, 95% CI = [8.28, Inf], k = 4 (Bonferroni adjusted two-tailed t test), an orientation-specific threshold elevation aftereffect <ref type="bibr" target="#b6">(Blakemore &amp; Nachmias, 1971;</ref><ref type="bibr" target="#b67">Regan &amp; Beverley, 1985)</ref>.</p><p>Adding congruent imagery following the congruent adapters during the blank gap led to no significant difference in hit rate compared with congruent adapters alone (Fig. <ref type="figure" target="#fig_2">2B</ref>, middle-left blue bar), M = -1.39%, SEM ±2.99%, t(18) = 0.466, p = 2.5872, 95% CI = <ref type="bibr">[-4.89, 7.68]</ref>, k = 4 (Bonferroni adjusted two-tailed t test). Strikingly, adding incongruent imagery after the incongruent adapter (i.e., imagining the same orientation as the adapter but orthogonal to the test) led to a significant decrement in the hit rate compared with the incongruent adapter alone (Fig. <ref type="figure" target="#fig_2">2B</ref>, rightmost blue bar), M = -7.35%, SEM ±2.54%, t(18) = 2.892, p = 0.0388, 95% CI = [2.01, 12.69], k = 4 (Bonferroni adjusted twotailed t test). To assess potential response biases during this experiment, one third of trials were empty with only the visual noise presented at test. For these empty trials, participants made 21% false alarms on average, incorrectly indicating they had seen a grating. However, the orientation selected during false alarms was equally likely to be congruent or incongruent to imagery (Supplementary Fig. <ref type="figure">3</ref> in the Supplemental Material), M = -0.0025%, SEM ±7.4%, t(18) = -0.03, p = .97, 95% CI = <ref type="bibr">[-15.79, 15.3]</ref> (two-tailed t test), suggesting no overt decisional bias. Hence, imagery's suppressive effect on orthogonal orientation discrimination was likely driven by perceptual rather than a high-level decisional bias. These data suggest that imagery exerts its effect by weakening the nonimagined grating representation rather than resetting the state of adaption, thus effectively acting as a modulator, attenuating the nonimagined representations. This provides novel evidence for the proposed modulation hypothesis of mental imagery (Koenig-Robert &amp; Pearson, 2021): that imagery might be down-regulating nonimagined feature processing.</p><p>We further wanted to investigate whether perceptual adapters had any impact on the false-alarm rates and if these could reveal some sort of attention effect or criterion shift. We therefore analyzed whether false alarms were impacted by the presence of an adapter before the test stimuli. We found that false alarms (i.e., participants stating they saw a grating of either orientation on blank test trials) were significantly higher when following an adapter compared with the nonadapter condition (Supplementary Fig. <ref type="figure">9</ref> in the Supplemental</p><p>Bell Press spacebar to start trial Response Adapter Imagery Target Up for vertical Right for horizontal Down for nothing Congruent trial Response Discrimination Experiment Imagery Suppressed Non-Imagined Percepts Suppression Evident Without Prior Adapter 0 -20 20 Congruent Imagery Incongruent Imagery a b c Change in Hits (%) 0 -20 -40 Congruent Adapter Congruent Adapter + Imagery Incongruent Adapter Incongruent Adapter + Imagery 20 * * * * * * * * * n.s Material), M = 14.58%, SEM ±3.58%, t(18) = 4.0728, p = 7.1423e-04, 95% CI = [0.0706, 0.2210] (two-tailed t test, noncorrected). However, there was no significant difference in congruent or incongruent false alarms (Supplementary Fig. <ref type="figure">10</ref> in the Supplemental Material), M = 1.33%, SEM ±1.15%, t(19) = 1.1587, p = 0.2617, 95% CI = [-0.0108, 0.0375] (two-tailed t test, noncorrected). This means that participants were equally likely to state that they had seen either orientation during blank trials regardless of the orientation of the preceding adapter. Thus, as in the imagery condition, perceptual adapters were not driving a criterion shift toward or away from their orientation.</p><p>To further ensure that the adapter prior to imagery was not somehow changing the nature of imagery, we ran a follow-up experiment without the adapters (see Method). Incongruent imagery led to significant reduction in discrimination accuracy compared with congruent imagery (Fig. <ref type="figure" target="#fig_2">2C</ref>), M = -10.69%, SEM ±3.17%, t(10) = 3.37, p = .007, 95% CI = [-17.75, -3.62] (two-tailed t test), and no-imagery baseline (Fig. <ref type="figure" target="#fig_2">2C</ref>), M = -8.48%, SEM ±2.46%, t(10) = -3.454, p = .012, 95% CI = [-13.96, -3], k = 2 (Bonferroni adjusted two-tailed t test). In other words, participants got worse at the discrimination task after imagery of the orthogonal orientation, not better. Interestingly, this is the opposite effect typically found postadaptation to orthogonal perceptual gratings <ref type="bibr" target="#b19">(Clifford et al., 2001</ref><ref type="bibr" target="#b18">(Clifford et al., , 2003;;</ref><ref type="bibr" target="#b78">Westheimer &amp; Gee, 2002</ref><ref type="bibr">, 2003)</ref>. These results further suggest that imagery mainly attenuated the representations of nonimagined features (orientation), rather than resetting the adaptation to the baseline, and provide further evidence for imagery behaving in ways that are often opposite to perception. Interestingly, here congruent imagery did not lead to a significant increase in accuracy compared with baseline (Fig. <ref type="figure" target="#fig_2">2C</ref>), M = 2.21%, SEM ±2.78, t(10) = 0.79, p = 0.89, 95% CI = <ref type="bibr">[-3.98, 8.4]</ref>, k = 2 (Bonferroni adjusted two-tailed t test), a result not in line with previous priming research <ref type="bibr" target="#b37">(Ishai &amp; Sagi, 1995;</ref><ref type="bibr" target="#b59">Pearson, 2019)</ref>. However, trials rated as more vivid did trend toward stronger priming compared with low-vividness trials (Supplementary Fig. <ref type="figure">4</ref> in the Supplemental Material), t(10) = 1.35, p = .1, 95% CI = [-Inf, 2.63] (acrosssubjects one-tailed t test, noncorrected).</p><p>Interestingly, vividness during incongruent imagery showed an opposite trend, with high-vividness trials trending toward significantly lower hits than lowvividness trials (Supplementary Fig. <ref type="figure">4</ref> in the Supplemental Material), t(10) = 1.27, p = .12, 95% CI = [-4, Inf] (across-subjects one-tailed t test). Furthermore, congruent-imagery trials that led to hits had significantly higher average vividness scores compared with hits that followed incongruent-imagery trials, t(10) = 2.04, p = .0343, 95% CI = [3.87, Inf] (across-subjects one-tailed t test, noncorrected). This shows that imagery vividness was positively correlated with discrimination accuracy for congruent imagery and negatively correlated with incongruent imagery. Importantly, this experiment also included empty catch trials to assess bias. On these trials, participants made an average of 16.32% false alarms and had no significant bias toward congruent or incongruent gratings (Supplementary Fig. <ref type="figure">5</ref> in the Supplemental Material), t(10) = 2.09, p = .064, 95% CI = [-0.2, 6.7] (two-tailed t test, noncorrected).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Overall, our results provide novel behavioral evidence that imagery and perceptual representations are sustained by different neural mechanisms. Across multiple experiments and replications, we show that although weak perception and imagery can seemingly have similar functional effects on subsequent perception (facilitatory), the two processes seem to have different representational mechanisms. When in a state of adaptation, weak perception was additive, increasing the level of adaptation, as "read out" by greater rivalry suppression. Imagery was nonadditive, and actually subtractive, meaning that it eliminated the effects of prior adaptation on rivalry. Further, we show that these effects are linked to imagery vividness, they are liable to disruption by concurrent uniform background luminance, and biases in rivalry reporting can be ruled out by the veridical catch trials.</p><p>Our visual discrimination experiments showed that imagery was not simply reversing the state of adaptation and "refreshing" imagined feature processing. Instead, the data suggest that imagery mainly drives suppression of nonimagined feature representations, which cancelled out the suppressive effects of prior adapters on rivalry. Together, these data suggest that imagined visual representations may, in part, be formed by suppressing nonimagined representations. Thus, unlike perception, which predominantly drives neuronal spikes, imagery's effect on early visual areas might be operating by a mechanism of neural modulation possibly in conjunction with weaker excitation rather than chiefly excitation alone.</p><p>There are, however, other possible interpretations of these results, as the observation that imagery did not increase adaptation does not necessarily rule out excitatory-only accounts of imagery. It is possible that imagery activates a representation that is sufficiently distinct from perceptual representations to not increase adaptation. However, several studies have shown that imagery representations overlap with perception both functionally <ref type="bibr" target="#b13">(Chang et al., 2013;</ref><ref type="bibr" target="#b14">Chang &amp; Pearson, 2018;</ref><ref type="bibr" target="#b26">Dijkstra et al., 2021</ref><ref type="bibr" target="#b25">Dijkstra et al., , 2022;;</ref><ref type="bibr" target="#b38">Keogh et al., 2020;</ref><ref type="bibr" target="#b39">Keogh &amp; Pearson, 2011;</ref><ref type="bibr" target="#b63">Pearson et al., 2011;</ref><ref type="bibr" target="#b60">Pearson &amp; Brascamp, 2008;</ref><ref type="bibr" target="#b71">Sherwood &amp; Pearson, 2010)</ref> and spatially <ref type="bibr" target="#b17">(Cichy et al., 2012;</ref><ref type="bibr" target="#b23">Dijkstra et al., 2017</ref><ref type="bibr" target="#b24">Dijkstra et al., , 2019;;</ref><ref type="bibr" target="#b31">Ganis et al., 2004;</ref><ref type="bibr" target="#b57">Naselaris et al., 2015)</ref>. Furthermore, outside of binocular rivalry, imagery has been shown to produce adaptation aftereffects akin to perceptual adapters <ref type="bibr" target="#b56">(Mohr et al., 2009</ref><ref type="bibr" target="#b55">(Mohr et al., , 2011;;</ref><ref type="bibr" target="#b80">Winawer et al., 2010;</ref><ref type="bibr" target="#b83">Zamuner et al., 2017)</ref>. Thus, that imagery was nonadditive to perceptual adaptation was surprising given the evidence for representational overlap with perception. Further, even with sufficient nonoverlap to explain the nonadditive effect, nonoverlapping representations would not explain the suppression reversal effect back to baseline that we observed in our results.</p><p>Based on our findings, it appears that the most parsimonious explanation is that mental imagery uses inhibition as a mechanism to construct perception-like visual representations <ref type="bibr" target="#b44">(Koenig-Robert &amp; Pearson, 2021)</ref>. This is supported by the fact that mental imagery was nonadditive to adapter-induced suppression and, indeed, seems to reverse it. Mental imagery reversed suppression in rivalry and suppressed nonimagined feature discrimination. These findings suggest that mental imagery is likely using inhibition as a key mechanism to build its visual representations rather than solely excitation.</p><p>The neurophysiological mechanism behind the striking phenomenological differences between imagery and perception might then be due to the neural mechanisms by which the two different types of representations are formed: modulation and excitation <ref type="bibr" target="#b44">(Koenig-Robert &amp; Pearson, 2021)</ref>. Results from functional magnetic resonance imaging research, showing the blood-oxygen-level-dependent (BOLD) response from imagery, have often been interpreted as evidence for imagery driving spiking in visual cortex <ref type="bibr" target="#b0">(Albers et al., 2013;</ref><ref type="bibr" target="#b16">Chen et al., 1998;</ref><ref type="bibr" target="#b46">Kosslyn &amp; Thompson, 2003;</ref><ref type="bibr" target="#b54">Mellet et al., 2000;</ref><ref type="bibr" target="#b57">Naselaris et al., 2015;</ref><ref type="bibr" target="#b58">O'Craven &amp; Kanwisher, 2000;</ref><ref type="bibr" target="#b66">Reddy et al., 2010;</ref><ref type="bibr" target="#b73">Slotnick et al., 2005;</ref><ref type="bibr" target="#b74">Stokes et al., 2009;</ref><ref type="bibr" target="#b77">Thirion et al., 2006)</ref>, even though BOLD responses are produced by both excitatory and inhibitory presynaptic inputs <ref type="bibr" target="#b53">(Logothetis, 2008)</ref>. However, our data suggest and electrophysiological work has shown that feedback more often modulates existing spiking activity in early visual areas, rather than generating spiking de novo <ref type="bibr" target="#b11">(Bullier et al., 2001;</ref><ref type="bibr" target="#b34">Huang et al., 2007</ref><ref type="bibr" target="#b35">Huang et al., , 2017;;</ref><ref type="bibr" target="#b36">Hupé et al., 1998)</ref>. While afferent perception drives spiking in visual cortex, imagery feedback signals may in part form representations via modulation of ongoing activity by downregulating neural activity associated with nonimagined feature processing. This down-regulation is evident in the deleterious effects of imagery on perceptual discrimination and the reversal of adapter effects in binocular rivalry. Thus, our results call for further investigation to move imagery research beyond the common heuristic that imagined representations are simply a "weak form of perception."</p><p>Interestingly, prior research has suggested that during visual imagery, the auditory cortex is deactivated <ref type="bibr" target="#b1">(Amedi et al., 2005)</ref>. Likewise, in our data, it would seem that nonimagined features are deactivated or suppressed. This suggests that feedback signals inducing a mental image are modulatory, suppressing neural activity coding for nonrelevant processing, as seen in recent work on attention <ref type="bibr" target="#b20">(Couperus &amp; Mangun, 2010;</ref><ref type="bibr" target="#b21">Daffner et al., 2012;</ref><ref type="bibr" target="#b32">Gazzaley et al., 2005;</ref><ref type="bibr" target="#b50">Lin, 2014;</ref><ref type="bibr" target="#b81">Wühr &amp; Frings, 2008)</ref> and working memory <ref type="bibr" target="#b28">(Feldmann-Wüstefeld &amp; Vogel, 2019;</ref><ref type="bibr" target="#b30">Fukuda &amp; Vogel, 2009;</ref><ref type="bibr" target="#b69">Sawaki &amp; Luck, 2011;</ref><ref type="bibr" target="#b84">Zanto &amp; Gazzaley, 2009)</ref>. In previous electrophysiology work, attention has been shown to facilitate enhancement of signals driven by the attended stimulus while suppressing signals driven by the unattended stimulus <ref type="bibr" target="#b29">(Forschack et al., 2017)</ref>. Is it possible that imagery is using a similar mechanism on the endogenous ongoing activity in the brain (Koenig-Robert &amp; Pearson, 2021)? As both imagery and attention use feedback mechanisms to modulate activity in the visual cortex, it is likely imagery would make use of similar suppressive mechanisms to attention.</p><p>Previous studies have shown that imagery can facilitate perceptual detection, likely through increasing stimulus specific sensory evidence <ref type="bibr" target="#b26">(Dijkstra et al., 2021</ref><ref type="bibr" target="#b25">(Dijkstra et al., , 2022;;</ref><ref type="bibr" target="#b37">Ishai &amp; Sagi, 1995)</ref>. Our findings provide additional insight into how imagery might facilitate perceptual processing through inhibition. Indeed, imagery may add stimulus-specific perceptual information via the mechanisms of inhibition to reduce sensory noise. Normalization models of neural activity suggest that the strength of stimulus-specific neural responses are determined by a ratio of stimulus drive (i.e., stimulus-specific excitatory activity) and noise (i.e., excitatory activity of nonpreferred neurons; <ref type="bibr" target="#b12">Carandini &amp; Heeger, 2012)</ref>. This means that the strength of a stimulus's sensory representation can be increased by increasing the intensity of the stimulus (e.g., by increasing its gain). However, the strength of the representation can also be enhanced by reducing irrelevant nonpreferred activity (i.e., noise), which increases the relative difference between stimulus input activity and noise. This theoretical framework provides a plausible avenue for understanding how imagery might increase stimulus-specific sensory evidence through inhibition. Similar results have been observed using attention, which has been shown to sharpen selectivity and neural responses of attended-to stimuli through inhibition of nonattended feature processing <ref type="bibr" target="#b3">(Bartsch et al., 2017;</ref><ref type="bibr" target="#b51">Ling et al., 2009;</ref><ref type="bibr" target="#b52">Liu et al., 2007)</ref>.</p><p>The lack of facilitation results observed in our studies could be due to mechanistic or methodological limitations. It is possible that the facilitation of discrimination through increased excitatory activity was too weak to alter discrimination accuracy in the presence of robust bottom-up driven neuronal adaptation (Fig. <ref type="figure" target="#fig_2">2B</ref>). Furthermore, the absence of facilitation in the no-adapter experiment (Fig. <ref type="figure" target="#fig_2">2C</ref>) might be due to task difficulty. Considering that longer periods of imagery cause stronger facilitatory effects <ref type="bibr">(Pearson et al., 2008)</ref>, increasing the imagery time before test might improve this. Interestingly, adaptation effects can last for varying durations, ranging from milliseconds to minutes or possibly longer <ref type="bibr" target="#b27">(Dragoi et al., 2002;</ref><ref type="bibr" target="#b45">Kohn, 2007)</ref>, and the effects of mental imagery on subsequent perception have been shown to persist for at least 5 s <ref type="bibr">(Pearson et al., 2008)</ref> and up to 5 min <ref type="bibr" target="#b37">(Ishai &amp; Sagi, 1995)</ref>. Taken together, these findings suggest that the inhibition induced by mental imagery may persist for some time, modulating subsequent perceptual processing. Importantly, our rivalry and discrimination stimuli were presented immediately at release of imagery (see Figs. <ref type="figure">1B</ref> and <ref type="figure" target="#fig_2">2A</ref>), suggesting the observed effects were independent of hysteresis effects. As a result, it remains uncertain whether the inhibitory effects of imagery persist over a delay, similar to the way that adaptation and facilitation effects appear to.</p><p>Last, as the experiments were behavioral, it is not possible to completely rule out explanations of higherlevel processes beyond the visual cortex. We did, however, use multiple methods to control for this. Previous research has shown luminance disrupts imagery but not other higher-order cognitions, such as attention <ref type="bibr" target="#b39">(Keogh &amp; Pearson, 2011;</ref><ref type="bibr">Pearson et al., 2008;</ref><ref type="bibr" target="#b71">Sherwood &amp; Pearson, 2010)</ref>. Here we showed that imagery's reversal of adapter suppression was significantly weakened by increased irrelevant background luminance. Additionally, trials in which participants rated their imagined gratings as more vivid led to stronger reversal of adapter suppression in rivalry and increased suppression of incongruent features during visual discrimination. Thus, the sensory production of mental images was important to our observed effects. Moreover, during false-alarm trials, participants showed no evidence of criterion shifts, as the false alarms were equally likely to be congruent or incongruent with the imagined or adapted stimulus. If imagery was simply influencing participants to guess more liberally in line with or away from imagined features, we would expect this to appear in participants' decisions here.</p><p>Another alternative explanation is that imagery was abolishing sensory history altogether, returning rivalry dominance to chance. Although we did not run an imagery-only condition for rivalry, extensive prior research has shown imagery's facilitatory effects on subsequent rivalry dominance <ref type="bibr" target="#b13">(Chang et al., 2013;</ref><ref type="bibr" target="#b14">Chang &amp; Pearson, 2018;</ref><ref type="bibr" target="#b38">Keogh et al., 2020;</ref><ref type="bibr" target="#b39">Keogh &amp; Pearson, 2011;</ref><ref type="bibr" target="#b63">Pearson et al., 2011;</ref><ref type="bibr" target="#b60">Pearson &amp; Brascamp, 2008;</ref><ref type="bibr" target="#b71">Sherwood &amp; Pearson, 2010)</ref>, showing that imagery biases rather than neutralizes perception. Additionally, if imagery abolished sensory history, prior congruent adaptation should have been reversed in discrimination tasks. However, we show a suppression effect of incongruent imagery on nonimagined feature discrimination with and without prior adaptation and no effect of imagery following congruent adapters. Thus altogether, our study contributes with fundamental psychophysical evidence while providing a novel framework for future physiological research to further elucidate the possible neural machinery of the observed suppression effect driven by mental imagery.</p><p>Evidence links conscious awareness with the levels of cortical activity <ref type="bibr" target="#b5">(Beck et al., 2006;</ref><ref type="bibr" target="#b7">Boehler et al., 2008;</ref><ref type="bibr" target="#b22">Dehaene et al., 2001;</ref><ref type="bibr" target="#b68">Ress &amp; Heeger, 2003;</ref><ref type="bibr" target="#b72">Silvanto et al., 2005;</ref><ref type="bibr" target="#b82">Wyart &amp; Tallon-Baudry, 2009)</ref>. Hence it follows that a neural modulatory mechanism, such as that proposed here for imagery, would be inherently limited in its ability to produce strong perception-like qualia. In other words, if imagery is better characterized as modulatory (as our data suggest), then imagery would have an inherent mechanistic upper limit in terms of its degraded, vague, or weak qualia. Such a functional mechanism might for most of us condemn imagery to always be phenomenologically different from perception. These data also have implications for the interpretation of much of the behavioral imagery work using binocular rivalry, which has been interpreted as prior imagery priming perception <ref type="bibr" target="#b14">(Chang &amp; Pearson, 2018;</ref><ref type="bibr" target="#b59">Pearson, 2019;</ref><ref type="bibr">Pearson et al., 2008</ref><ref type="bibr" target="#b62">Pearson et al., , 2015))</ref>. However, the current data suggest that imagery might be suppressing representations of nonimagined features, thereby mimicking priming in the binocular rivalry experiments by weakening the orthogonal orientation. One of the limitations of the current work is that we investigated only imagery of simple oriented gratings. It remains unknown if these trends would extend to complex or dynamic imagery (e.g., faces or motion). Although imagery was not additive to adaptation here, imagery induced adaptation has been observed with higher-level stimuli, such as motion <ref type="bibr" target="#b33">(Gilden et al., 1995;</ref><ref type="bibr" target="#b80">Winawer et al., 2010)</ref>. As the majority of feedback connections being modulatory is likely only the case for lower-level areas like V1 and V2 <ref type="bibr" target="#b34">(Huang et al., 2007</ref><ref type="bibr" target="#b35">(Huang et al., , 2017;;</ref><ref type="bibr" target="#b36">Hupé et al., 1998)</ref>, it is possible we would see different effects when imagery is reliant on representations coded by higher-level brain areas.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Discrimination experiment procedure and results. (a) Procedure for follow-up discrimination experiment. Participants viewed an adapter followed by a blank gap and then a weakly presented grating within visual noise. Congruent trials had adapters with orientations the same as the test grating, and incongruent trials had orthogonally oriented adapters to test. The adapter and imagery orientations were always the same regardless of condition. For imagery trials, participants imagined the oriented adapter as vividly as possible during the blank. (b) Congruent perceptual adapters led to stronger suppression of discrimination accuracy than incongruent adapters. However, imagining congruent adapters had no effect on discrimination accuracy, whereas imagining incongruent adapters did. This result suggests that imagery drove suppression effects in rivalry through inhibition of nonimagined visual feature processing. (c) Effect of imagery on discrimination accuracy without adapters presented prior. Incongruent imagery led to less discrimination accuracy than baseline. All error bars represent standard error of the mean. An asterisk represents Bonferroni adjusted paired-sample t test p value less than .05; two asterisks, less than .025.</figDesc></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Sachiko Kinoshita Editor: Patricia J. Bauer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices</head><p>All data and analysis code for Experiments 1 through 5 are available at <ref type="url" target="https://osf.io/3q57t/?view_only=2a258ef4b5de4fa2a780959447067a07">https://osf.io/3q57t/?view_only=2a258ef4b5d  e4fa2a780959447067a07</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Shared representations for working memory and mental imagery in early visual cortex</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Toni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Dijkerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1427" to="1431" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Negative BOLD differentiates visual imagery and perception</title>
		<author>
			<persName><forename type="first">A</forename><surname>Amedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pascual-Leone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="859" to="872" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Apical drive-A cellular mechanism of dreaming</title>
		<author>
			<persName><forename type="first">J</forename><surname>Aru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Siclari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Storm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="440" to="455" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Attention to color sharpens neural population tuning via feedback processing in the human visual cortex hierarchy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Bartsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Loewe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Merkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Schoenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Hopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page" from="10346" to="10357" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Canonical microcircuits for predictive coding</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bastos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Usrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Mangun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="695" to="711" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Right parietal cortex plays a critical role in change blindness</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Muggleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="712" to="717" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The orientation specificity of two visual after-effects</title>
		<author>
			<persName><forename type="first">C</forename><surname>Blakemore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nachmias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="174" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rapid recurrent processing gates awareness in primary visual cortex</title>
		<author>
			<persName><forename type="first">C</forename><surname>Boehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schoenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-J</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Hopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="8742" to="8747" />
			<date type="published" when="2008">2008</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Orientation and spatial frequency selectivity of adaptation to color and luminance gratings</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Switkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Valois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="841" to="856" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The psychophysics toolbox</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Brainard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Flash suppression and flash facilitation in binocular rivalry</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Brascamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Knapen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kanai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van Ee</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The role of feedback connections in shaping the responses of visual cortical neurons</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bullier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-M</forename><surname>Hupé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Girard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Progress in brain research</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Casanova</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Ptito</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="193" to="204" />
			<date type="published" when="2001">2001</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Normalization as a canonical neural computation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The functional effects of color perception and color imagery</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1167/13.10</idno>
		<ptr target="https://doi.org/10.1167/13.10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The functional effects of prior motion imagery and motion perception</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The functional effects of voluntary and involuntary phantom color on conscious awareness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">1006</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human primary visual cortex and lateral geniculate nucleus activation during visual imagery</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X.-H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Tank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ugurbil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroReport</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3669" to="3674" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Imagery and perception share cortical representations of content and location</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Cichy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heinzle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Haynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="372" to="380" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Opposing views on orthogonal adaptation: A reply to Westheimer and Gee</title>
		<author>
			<persName><forename type="first">C</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pianta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="717" to="719" />
			<date type="published" when="2002">2003. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Orthogonal adaptation improves orientation discrimination</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Wyatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wenderoth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="159" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Signal enhancement and suppression during visual-spatial selective attention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Couperus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Mangun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1359</biblScope>
			<biblScope unit="page" from="155" to="177" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Does modulation of selective attention to features reflect enhancement or suppression of neural activity</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Daffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Zhuravleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Tarbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Haring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Rentz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Holcomb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="407" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cerebral mechanisms of word masking and unconscious repetition priming</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Naccache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Le Bihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-F</forename><surname>Mangin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Poline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rivière</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="752" to="758" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Vividness of visual imagery depends on the neural overlap with perception in visual areas</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Gerven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1367" to="1373" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shared neural mechanisms of visual perception and imagery</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Gerven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="423" to="434" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagery adds stimulus-specific sensory evidence to perceptual detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mistaking imagination for reality: Congruent mental imagery leads to more liberal perceptual detection</title>
		<author>
			<persName><forename type="first">N</forename><surname>Dijkstra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fleming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="page">104719</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamics of neuronal sensitivity in visual cortex and local feature discrimination</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dragoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="883" to="891" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural evidence for the contribution of active suppression during working memory filtering</title>
		<author>
			<persName><forename type="first">T</forename><surname>Feldmann-Wüstefeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="529" to="543" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Global enhancement but local suppression in featurebased attention</title>
		<author>
			<persName><forename type="first">N</forename><surname>Forschack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="619" to="627" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Human variation in overriding attentional capture</title>
		<author>
			<persName><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="8726" to="8733" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Brain areas underlying visual mental imagery and visual perception: An fMRI study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ganis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Brain Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="241" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Top-down enhancement and suppression of the magnitude and speed of neural activity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gazzaley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Cooney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcevoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="507" to="517" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neural adaptation of imaginary visual motion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gilden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The effects of reversible inactivation of postero-temporal visual cortex on neuronal activities in cat&apos;s area 17</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dreher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1138</biblScope>
			<biblScope unit="page" from="111" to="128" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Silencing &quot;topdown&quot; cortical signals affects spike-responses of neurons in cat&apos;s &quot;intermediate&quot; visual cortex</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dreher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neural Circuits</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cortical feedback improves discrimination between figure and background by V1, V2 and V3 neurons</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hupé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lomber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bullier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">394</biblScope>
			<biblScope unit="issue">6695</biblScope>
			<biblScope unit="page" from="784" to="787" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Common mechanisms of visual imagery and perception</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ishai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<biblScope unit="issue">5218</biblScope>
			<biblScope unit="page" from="1772" to="1774" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cortical excitability controls the strength of mental imagery</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Article e50232</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mental imagery and visual working memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Article e29221</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention driven phantom vision: Measuring the sensory strength of attentional templates and their relation to visual mental imagery and aphantasia</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="issue">1817</biblScope>
			<biblScope unit="page">20190688</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brainard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pelli</surname></persName>
		</author>
		<ptr target="https://pure.mpg.de/rest/items/item_1790332/component/file_3136265/content" />
		<title level="m">What&apos;s new in Psychtoolbox-3?</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Distinct feedforward and feedback effects of microstimulation in visual cortex reveal neural mechanisms of texture segregation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Klink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dagnino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-A</forename><surname>Gariel-Mathis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="209" to="220" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Decoding the contents and strength of imagery before volitional engagement</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenig-Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Why do imagery and perception look and feel so different?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Koenig-Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<biblScope unit="issue">1817</biblScope>
			<biblScope unit="page">20190703</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Visual adaptation: Physiology, mechanisms, and functional benefits</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3155" to="3164" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">When is early visual cortex activated during visual mental imagery</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="723" to="746" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Measuring thought-control failure: Sensory mechanisms and individual differences</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Leys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Koenig-Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="811" to="821" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Disentangling visual imagery and perception of real-world objects</title>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4064" to="4073" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Conditioning the mind&apos;s eye: Associative learning with voluntary mental imagery</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Khuu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="390" to="400" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Voluntary spatial attention induces spatial facilitation and object-centered suppression</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="968" to="982" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">How spatial and feature-based attention affect the gain and tuning of population responses</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1194" to="1204" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Feature-based attention modulates orientation-selective responses in human visual cortex</title>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="323" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">What we can do and what we cannot do with fMRI</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="issue">7197</biblScope>
			<biblScope unit="page" from="869" to="878" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Functional anatomy of high-resolution visual mental imagery</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mellet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tzourio-Mazoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bricogne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mazoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kosslyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="109" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Orientation-specific aftereffects to mentally generated lines</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Mohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sireteanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="272" to="290" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Orientation-specific adaptation to mentally generated lines in human visual cortex</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Mohr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sireteanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="384" to="391" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A voxel-wise encoding model for early visual areas decodes mental images of remembered scenes</title>
		<author>
			<persName><forename type="first">T</forename><surname>Naselaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Olman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Stansbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ugurbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="215" to="228" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mental imagery of faces and places activates corresponding stimulus-specific brain regions</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>O'craven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1013" to="1023" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The human imagination: The cognitive neuroscience of visual mental imagery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="624" to="634" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Sensory memory for ambiguous vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brascamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="334" to="341" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The functional impact of mental imagery on conscious perception</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="982" to="986" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Mental imagery: Functional mechanisms and clinical applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Naselaris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="590" to="602" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Evaluating the mind&apos;s eye: The metacognition of visual imagery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1535" to="1542" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The VideoToolbox software for visual psychophysics: Transforming numbers into movies</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="437" to="442" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Training visual imagery: Improvements of metacognition, but not imagery strength</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Rademaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">224</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Reading the mind&apos;s eye: Decoding category information during mental imagery</title>
		<author>
			<persName><forename type="first">L</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tsuchiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="818" to="825" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Postadaptation orientation discrimination</title>
		<author>
			<persName><forename type="first">D</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beverley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="155" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Neuronal correlates of perception in early visual cortex</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ress</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="414" to="420" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Active suppression of distractors that match the contents of visual working memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sawaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="956" to="972" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">On the actions that one nerve cell can have on another: Distinguishing &quot;drivers&quot; from &quot;modulators</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guillery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7121" to="7126" />
			<date type="published" when="1998">1998</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Closing the mind&apos;s eye: Incoming luminance signals disrupt visual imagery</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sherwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Article e15217</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Striate cortex (V1) activity gates awareness of motion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Silvanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cowey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="144" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Visual mental imagery induces retinotopically organized activation of early visual areas</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Slotnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1570" to="1583" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Top-down activation of shape-specific population codes in visual cortex during mental imagery</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cusack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1565" to="1572" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Long-lasting, long-range detection facilitation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="2591" to="2599" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Human perceptual learning by mental imagery</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Tartaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bamert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Mast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Herzog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="2081" to="2085" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Inverse retinotopy: Inferring the visual content of images from brain activation patterns</title>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-B</forename><surname>Poline</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lebihan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1104" to="1116" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Orthogonal adaptation and orientation discrimination</title>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="2339" to="2343" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Opposing views on orthogonal adaptation: A response to Clifford</title>
		<author>
			<persName><forename type="first">G</forename><surname>Westheimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smith</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pianta</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="721" to="722" />
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A motion aftereffect from visual imagery of motion</title>
		<author>
			<persName><forename type="first">J</forename><surname>Winawer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Huk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boroditsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="276" to="284" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A case for inhibition: Visual attention suppresses the processing of irrelevant objects</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wühr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Frings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="130" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">How ongoing fluctuations in human visual cortex predict perceptual awareness: Baseline shift versus decision bias</title>
		<author>
			<persName><forename type="first">V</forename><surname>Wyart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tallon-Baudry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="8715" to="8725" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Visual perception and visual mental imagery of emotional faces generate similar expression aftereffects</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zamuner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oxner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Hayward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Consciousness and Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="171" to="179" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Neural suppression of irrelevant information underlies optimal working memory performance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Zanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gazzaley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3059" to="3066" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
