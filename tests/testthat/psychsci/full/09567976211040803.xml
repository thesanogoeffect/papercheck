<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Moral Frames Are Persuasive and Moralize Attitudes; Nonmoral Frames Are Persuasive and De-Moralize Attitudes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Rabia</forename><forename type="middle">I</forename><surname>Kodapanakkal</surname></persName>
							<email>r.i.kodapanakkal@tilburguniversity.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">Tilburg University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Mark</forename><forename type="middle">J</forename><surname>Brandt</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Michigan State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christoph</forename><surname>Kogler</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">Tilburg University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ilja</forename><surname>Van Beest</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">Tilburg University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Social Psychology</orgName>
								<orgName type="institution">Tilburg University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Moral Frames Are Persuasive and Moralize Attitudes; Nonmoral Frames Are Persuasive and De-Moralize Attitudes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">11EB1B626DEACB24C827B8E7AA25D675</idno>
					<idno type="DOI">10.1177/09567976211040803</idno>
					<note type="submission">Received 3/26/21; Revision accepted 8/2/21</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-06-03T13:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=0, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>persuasion</term>
					<term>moral conviction</term>
					<term>moralization</term>
					<term>de-moralization</term>
					<term>compromise</term>
					<term>open data</term>
					<term>open materials</term>
					<term>preregistered</term>
				</keywords>
			</textClass>
			<abstract xml:lang="sv">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>moral framing;</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This may be premature. Moral framing and reframing strategies could have unintended side effects that limit their potential to bridge divides. We consider two. First, these strategies could increase the moral relevance people attach to an attitude, leaving people persuaded and with their attitudes moralized. Second, these strategies could decrease people's willingness to compromise, leaving people persuaded but with their attitudes entrenched. For example, an individual who thinks the use of hiring algorithms to hire employees is morally right because it is fairer and accurate could be persuaded with moral arguments highlighting that these technologies can be biased and unfair. However, this may lead to moralization of the attitude as well as a decreased willingness to compromise on the issue. Persuading and entrenching people may be a viable goal if one considers the changed attitude to be the morally correct one, but if moral framing and reframing are to be used to bridge political divides, such side effects are antithetical to the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential Side Effects</head><p>In both moral framing and reframing strategies, the moral arguments used for persuasion could also induce change in people's moral convictions. The content of the moral arguments is purposefully similar to factors that drive the process of moralization. For example, research suggests that moralization is based on the intuitive perception of harm (e.g., <ref type="bibr" target="#b28">Schein &amp; Gray, 2018)</ref>, strong emotional reactions <ref type="bibr" target="#b4">(Brandt et al., 2015;</ref><ref type="bibr" target="#b39">Wisneski &amp; Skitka, 2017)</ref>, or the linking of an attitude with a broader moral principle <ref type="bibr">(Feinberg et al., 2019;</ref><ref type="bibr" target="#b26">Rozin, 1999)</ref>. Moral arguments often contain all of these elements, tapping into people's moral emotions, perceptions of harm, and their broader moral principles (e.g., <ref type="bibr" target="#b11">Feinberg &amp; Willer, 2015;</ref><ref type="bibr" target="#b20">Luttrell et al., 2016</ref><ref type="bibr" target="#b21">Luttrell et al., , 2019))</ref>. These elements likely make the argument persuasive <ref type="bibr" target="#b11">(Feinberg &amp; Willer, 2015)</ref>, but they could also moralize the target attitude.</p><p>A secondary moralization effect may not be worrisome. Moralized attitudes can be constructive because they can increase people's political engagement and lead to more collective action and greater civic participation <ref type="bibr" target="#b23">(Mazzoni et al., 2015;</ref><ref type="bibr" target="#b29">Skitka &amp; Bauman, 2008;</ref><ref type="bibr" target="#b36">van Zomeren et al., 2011)</ref>. However, moralized attitudes are a double-edged sword and can also have effects that may be less constructive (at least in certain situations) because people who hold moralized attitudes are less willing to compromise (e.g., <ref type="bibr" target="#b8">Delton et al., 2020)</ref>, show more anger (e.g., <ref type="bibr" target="#b24">Mullen &amp; Skitka, 2006)</ref>, and are intolerant toward those with whom they disagree (e.g., <ref type="bibr" target="#b13">Garrett &amp; Bankert, 2020)</ref>.</p><p>We focus on a side effect that is particularly relevant for efforts at bridging moral and political divides: the willingness to compromise. Willingness to compromise in a democratic system recognizes pluralistic values and acts as an instrument to achieve mutual respect and stability. Resisting compromise and strongly favoring only one outcome can lead to a stalemate in governments in which problems go unresolved (see <ref type="bibr" target="#b27">Ryan, 2017)</ref>. People who hold strong moral convictions about their attitudes are less likely to compromise <ref type="bibr" target="#b6">(Clifford, 2019;</ref><ref type="bibr" target="#b8">Delton et al., 2020;</ref><ref type="bibr" target="#b27">Ryan, 2017)</ref> and are even less likely to identify procedures for resolving issues <ref type="bibr" target="#b30">(Skitka et al., 2005)</ref>. This is because moralized attitudes are particularly strong attitudes, connected to right and wrong, and are often viewed like objective facts <ref type="bibr" target="#b14">(Goodwin &amp; Darley, 2008;</ref><ref type="bibr" target="#b31">Skitka et al., 2021)</ref>. If one perceives the other side as holding an objectively wrong position, it does not make sense to compromise. For people who hold truly strong moral convictions, it would be akin to compromising on the answer to 2 + 2. Notably, if moral framing and reframing strategies induce an unwillingness to compromise, their utility in bridging divides will be curtailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statement of Relevance</head><p>Societies are divided over moral issues. One set of strategies to bridge these divides is to frame persuasive arguments in moral terms (e.g., "new technologies can cause harm and be used to discriminate against people") or use alternative moral values. These strategies have unintended side effects that reduce the possibility that they can bridge moral divides. We found two such side effects. The first is that moral frames increase moralization (one's attitude having a moral basis), and the second is that moral frames lower people's willingness to compromise. These results imply that current moral-persuasion strategies designed to bridge moral divides by changing attitudes could unintentionally increase those divides by further moralizing and entrenching people's attitudes. Scholars and practitioners should use these strategies cautiously and test for potential side effects in the domains in which they plan to use them. We also found that nonmoral frames were persuasive and demoralized people's attitudes. This strategy has the potential to persuade people but could also reduce the moral stakes by reducing levels of moralization.</p><p>There is some initial evidence for this curtailing. One study found that people exposed to moral rhetoric (compared with pragmatic rhetoric) used more absolutist reasoning and expressed more intense political attitudes (at least for two of the attitudes considered; <ref type="bibr" target="#b22">Marietta, 2008)</ref>. This study, however, was underpowered, did not directly measure moralization or compromise, and did not include a control condition. The latter omission is important because without a control condition, one cannot determine whether moral framing increases moralization or whether pragmatic framing decreases moralization. Another study <ref type="bibr" target="#b35">(Van Zant &amp; Moore, 2015)</ref> that included a moral, ambiguous, and pragmatic frame did not find any differences in moralization across the frames. However, very brief frames were used, which may not be sufficient to affect moralization. Nonmoral messages that contain pragmatic arguments highlighting economic and feasibility concerns can be persuasive for people who hold nonmoral attitudes and unpersuasive for those who hold moralized attitudes <ref type="bibr">(Luttrell et al., 2019, Study 1)</ref>. However, how these messages might affect moralization and the willingness to compromise is not known. Some research suggests that the consideration of financial costs can reduce the influence of moralization <ref type="bibr" target="#b2">(Bastian et al., 2015)</ref>, and others hint at using emotional de-escalation to reduce moralization <ref type="bibr" target="#b6">(Clifford, 2019;</ref><ref type="bibr" target="#b31">Skitka et al., 2021)</ref>. For example, emotional frames lead to greater attitude moralization compared with a control frame <ref type="bibr" target="#b6">(Clifford, 2019)</ref>, but whether nonemotional frames do the opposite is an empirical question yet to be tested. Nonmoral messages devoid of emotional content and containing economic concerns could potentially result in de-moralized attitudes and a greater willingness to compromise. By including moral, nonmoral, and control conditions, it is possible to test for unintended side effects of moral framing and reframing strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Current Research</head><p>We assessed whether moral and nonmoral frames affected people's moral convictions (Studies 1-3) and their willingness to compromise (Study 3) on their position. We also tested whether the frames were persuasive to ensure that any differences in moral convictions or compromise were not due to differential effectiveness at changing attitudes (Studies 1-3). We also explored potential mechanisms (e.g., emotions, perceptions of harm) driving changes in moral convictions (Studies 2 and 3). All the studies focused on persuading people to oppose new big-data technologies because these issues involve relatively new attitudes that are often discussed using moral language <ref type="bibr" target="#b7">(Corlett, 2002;</ref><ref type="bibr" target="#b17">Kleinberg et al., 2018)</ref> and because they have the potential to moralize those attitudes <ref type="bibr" target="#b19">(Kodapanakkal et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>We describe the method of all studies in parallel, highlighting the similarities and differences. These are summarized in Table <ref type="table" target="#tab_0">1</ref>. We used a pretest/posttest design with two time points for Studies 1 and 2. Study 3 had only one time point. In all studies, we randomly assigned participants to at least one moral frame, one nonmoral frame, or a control condition.</p><p>In Study 1, we assessed whether moral and nonmoral frames were persuasive and whether they affected moral conviction. These frames presented arguments opposing crime-surveillance technologies. The primary analyses in Study 1 were exploratory. 1 We found that the moral frames were persuasive and moralized people's attitudes, whereas nonmoral frames were persuasive but (marginally) de-moralized their attitudes.</p><p>We had three aims in Study 2. First, we wanted to replicate the moralization and de-moralization findings of Study 1. We predicted that the results would be the same as in Study 1 (the preregistration can be viewed at <ref type="url" target="https://osf.io/7rzx8/">https://osf.io/7rzx8/</ref>). Second, we wanted to explore possible cognitive and affective mechanisms that could drive the effects of moralization and de-moralization. Third, we wanted to see whether the findings of Study 1 would replicate in a different technology settinghiring algorithms.</p><p>We had three aims in Study 3. First, we aimed to replicate the moralization and de-moralization effects of Studies 1 and 2. Second, we aimed to further explore mechanisms of the de-moralization process intended to tap into a pragmatic reasoning style that might temper moralization. Third, we aimed to assess a second possible side effect: people's willingness to compromise. We expected that people in the moral condition would be less willing to compromise, whereas people in the nonmoral condition would be more willing to compromise. These predictions were preregistered (<ref type="url" target="https://osf.io/sqa9w/">https://osf.io/sqa9w/</ref>). The studies were reviewed and approved by the ethics review board of Tilburg University School of Social and Behavioral Sciences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>All studies were conducted online on Prolific (<ref type="url" target="http://www.prolific.co">www.pro- lific.co</ref>) with participants from the United States. Given the similarities in all the studies, participants who participated in one study were excluded from the participant pool of subsequent studies. In Studies 1 and 2, we conducted power analyses with the R package Declare-Design (Version 0.30.0; <ref type="bibr" target="#b3">Blair et al., 2022)</ref>, which indicated that a minimum sample of 500 participants per condition would be needed to achieve a standardized effect size (Cohen's d) of 0.18 (based on <ref type="bibr" target="#b38">Voelkel et al., 2020)</ref> with an α of .05 and 80% power. The effect size considered was for an interaction effect (i.e., the moral-reframing hypotheses; see Note 1). We estimated a minimum sample size of 2,000 participants for Study 1 (four betweensubject conditions) and 1,500 participants for Study 2 (three between-subject conditions). We aimed to recruit an additional 10% to account for attrition. The actual number of participants recruited at both Time 1 and Time 2 is shown in Table <ref type="table" target="#tab_0">1</ref>. For both studies, participants received £0.50 for completing the measures at the first time point (~4 min) and £0.40 for completing the measures at the second time point (~3 min). In both studies, there was a 1-week gap between the two time points, and the survey at Time 2 remained open for 1 week.</p><p>For Study 3, we calculated that a minimum sample size of 950 would be required to achieve a standardized effect size (Cohen's d) of 0.20 with an α of .05 and 80% power. The effect size was based on what we found in Study 2 for similar manipulations. We aimed for a higher sample size (at least 1,000) to account for participants who might not complete the study. Participants received £1 to complete the study, which was 8 min long. See Table <ref type="table" target="#tab_0">1</ref> for demographic statistics of all studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design and procedure</head><p>In Studies 1 and 2, participants first read a neutral description of the technology under consideration at Time 1. This description included factual information about who uses the technology and what the technology does. The wording was as neutral as possible without any persuasive arguments for or against the technology, and it did not mention any benefits or downsides of the technology. Participants read about a crime-surveillance technology in Study 1 and a hiring algorithm in Study 2. We used hiring algorithms in Study 2 because they differed from crime-surveillance technologies in two ways: Hiring algorithms are used mostly by private companies (not the government) and have the potential for discrimination instead of privacy violations, which are more problematic in crime-surveillance technologies (see <ref type="bibr" target="#b18">Kodapanakkal et al., 2020</ref>, for a justification of various technology domains).</p><p>After reading the descriptions, participants reported their support for the technology and the degree to which they felt that their attitude was based on a moral conviction. They also reported the extent to which their attitudes were grounded in specific moral foundations (see Note 1). Finally, they answered demographic questions related to age, gender, and political ideology. (See Tables <ref type="table" target="#tab_0">S1</ref> and <ref type="table" target="#tab_1">S2</ref> in the Supplemental Material available online for full descriptions of the technologies.) At Time 2, participants in Study 1 were randomly assigned to four conditions (harm-based moral, libertybased moral, nonmoral, and control) and participants in Study 2 were randomly assigned to three conditions (harm or fairness based, nonmoral, and control). The control message was the same as the neutral description presented at Time 1 for each study. The first part of all the other messages was the same as the control message. The second part of the messages included the potential disadvantages of the respective technology, and the third part presented a factual example of the disadvantage. In Study 1, the harm-based moral message included arguments that used keywords such as harm, misuse, and damage. The liberty-based moral message included keywords such as intrusive, violating freedom, and liberty. The nonmoral message was pragmatic and included arguments related to financial cost and the inefficiency of the technology; it contained keywords such as costly, unfeasible, and monetary costs. (For results of analyses testing the effectiveness of the materials, see Figs. S1, S2, and S3 in the Supplemental Material.) In Study 2, the nonmoral message had pragmatic arguments similar to those in Study 1. The moral message in Study 2 included harm-and fairness-based arguments that contained keywords such as immoral, harmful, bias, and consequences.</p><p>At Time 2, after reading the different messages, participants reported their support for the technology and the degree to which they felt that their attitude was based on a moral conviction. In Study 2, we additionally assessed potential mechanisms of moralization and de-moralization. Participants reported perceived risks and benefits of the technology and emotional reactions of anger, disgust, fear, feeling creeped out, and gratefulness toward the technology.</p><p>The procedure for Study 3 was exactly the same as in Time 2 of Study 2, in which participants were assigned to the three conditions that were used in Study 2. Next, they reported their attitude toward the technology in the study (attitude support) and moral conviction. Participants in Study 3 also reported other dimensions of attitude strength, such as how certain, central, and important their position was to them. This helped us understand whether moral conviction is affected like other dimensions of attitude strength are or whether it is affected in a unique way (cf. <ref type="bibr" target="#b30">Skitka et al., 2005)</ref>. After that, we assessed people's willingness to compromise using three measures: support for a political candidate, willingness to work with a manager, and willingness to compromise in an incentivized compromise game. In Study 3, we also assessed the same potential mechanisms for moralization and de-moralization measured in Study 2. To test for additional mechanisms of demoralization, we additionally measured the extent to which people weigh costs and benefits and how financially costly they find the technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures</head><p>Attitude support. Participants rated their attitude toward the respective technology with the following item on a 7-point Likert scale (1 = strongly oppose, 7 = strongly support): "To what extent do you support or oppose the use of the above technology?" Moral conviction. We assessed participants' moral conviction with a two-item moral-conviction scale (e.g., <ref type="bibr" target="#b30">Skitka et al., 2005)</ref>: "How much is your position on the use of this technology connected to your core moral beliefs and convictions?" and "How much is your position on the use of this technology connected to your beliefs about fundamental right or wrong?" Participants responded to the items on a 7-point Likert scale (1 = not at all, 7 = very much; Study 1, Time 1: r = .69; Study 1, Time 2: r = .73; Study 2, Time 1: r = .73; Study 2, Time 2: r = .79; Study 3: r = .79).</p><p>Potential mechanisms. Participants reported their perception of the risks of the technology by responding to questions such as, "This technology would be risky for people" (Study 1: α = .82; Study 2: α = .82; 1 = strongly disagree, 7 = strongly agree). They reported their perception of the benefits of technology by responding to questions such as, "This technology will help people obtain services they want" (Study 1, α = .93; Study 2, α = .89; 1 = strongly disagree, 7 = strongly agree). They also reported emotional reactions (anger, fear, disgust, creeped out, and gratefulness) toward the technology-for example, "Please indicate to what extent this technology makes you feel angry" (1 = not at all, 7 = very much). In Study 3, there were two additional measures: the extent to which participants weigh costs and benefits-"To what extent did you think about costs and benefits related to this hiring algorithm when deciding whether you support or oppose this algorithm?"-and the extent of financial cost-"To what extent did you think about how financially costly this hiring algorithm is when deciding whether you support or oppose this algorithm?" (1 = not at all, 7 = very much). These two measures were treated as separate constructs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Willingness to compromise.</head><p>Support for compromising and uncompromising political candidates. In Study 3, participants reported their likelihood of supporting two candidates who were competing for a mayoral nomination. The description was written such that without its mentioning "oppose" or "support," the candidates were portrayed as agreeing with the participant's position. Participants read the following:</p><p>Both candidates agree with your position on the use of this hiring algorithm. Candidate A is uncompromising and will vote against any proposal that does not support your position. Candidate B will dislike proposals that do not support your position, but will be willing to negotiate and make concessions in this area if it leads to a gain in other areas that are important to you.</p><p>Participants reported their support for the uncompromising and compromising candidates by answering the question, "How likely are you to support Candidate [A/B] for the nomination?" using a 7-point Likert scale (1 = not at all, 7 = very likely). This question was asked separately for each candidate. The order of the description for each candidate was randomized.</p><p>Willingness to work with compromising and uncompromising managers. In the second measure of compromise, participants reported their willingness to work with two managers who had the power to decide whether they would use the hiring algorithm or not. Again, the description was written such that, without its mentioning "oppose" or "support," the candidates were portrayed as agreeing with the participant's position. Participants read the following: Both managers agree with your position on this algorithm. Manager A is uncompromising and is not open to views on this algorithm that do not support your position. Manager B will dislike views that do not support your position, but is willing to negotiate and make concessions if it leads to a gain in other areas of the company that are important to you.</p><p>Participants reported their willingness to work with the uncompromising and compromising managers by answering the question, "How likely are you to work with Manager [A/B]?" using a 7-point Likert scale (1 = not at all, 7 = very likely). This question was asked separately for each manager. The order of the description for each manager was randomized.</p><p>Incentivized compromise game. The third measure of compromise was in the form of a fully incentivized economic game based on a modified version used in <ref type="bibr" target="#b8">Delton et al. (2020)</ref>. In this game, participants were presented with six different policies that ranged from fully implementing the technology to not implementing the technology at all. On the basis of their reported attitude, we told participants that they would be paired with a participant who had the opposite attitude. If participants selected the midpoint of the scale, they reported in a follow-up question whether they would support or oppose the algorithm if they really had to choose one side. Participants who supported the algorithm saw this description: "You said you SUPPORT the implementation of this algorithm. The other participant in this negotiation OPPOSES the implementation of this algorithm." Similarly, participants who opposed the algorithm saw this description: "You said you OPPOSE the implementation of this algorithm. The other participant in this negotiation SUPPORTS the implementation of this algorithm." Participants could choose policies that corresponded to different levels of compromise, and there would be a deal only if both participants picked the same policy. We operationalized compromise as the proportion of payoff to the opponent. The value of the proportion of payoff could be 0, .2, .4, .6, .8, and 1, depending on the policy they chose. A higher payoff for the opponent indicated higher compromise. For more details on the game, see "Details of Willingness to Compromise Measures" in the Supplemental Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The means of the baseline attitudes and moral-conviction measures are shown in Table <ref type="table">S4</ref> in the Supplemental Material. Results were output into Word using the R package tidystats (Version 0.5; <ref type="bibr" target="#b33">Sleegers, 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of condition on attitude support</head><p>We first tested whether the persuasive conditions were effective at persuading participants. To test this, we dummy-coded the condition variable (reference: control condition) in all three studies. In Studies 1 and 2, we regressed attitude support at Time 2 on dummycoded condition and attitude support at Time 1, so that the effects of condition indicated changes in attitude support between Time 1 and Time 2. In Study 3, we regressed attitude support on dummy-coded condition. Results are shown in Table <ref type="table" target="#tab_1">2</ref> and <ref type="table" target="#tab_0">Figure 1</ref>. Across all three studies, we found that compared with messages in the control condition, messages in both the moral and nonmoral conditions significantly persuaded participants to oppose the technology (ds = -0.78 to -0.42). These results show that all of the messages (moral or nonmoral) were persuasive to a similar degree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Side Effect 1: effect of condition on moral conviction</head><p>Results showed that all persuasive conditions were persuasive as intended, but was there a side effect of moral conviction? To test this, we dummy-coded the condition variable (reference: control condition) in all three studies. In Studies 1 and 2, we regressed moral conviction at Time 2 on dummy-coded condition and moral conviction at Time 1, so that the effects of condition indicated changes in moral conviction between Time 1 and Time 2. In Study 3, we regressed moral conviction on dummy-coded condition. Results are shown in Table <ref type="table" target="#tab_1">2</ref> and Figure <ref type="figure" target="#fig_0">2</ref>. Across all three studies, we found that, compared with participants in the control condition, participants' attitudes in the moral conditions were significantly more moralized (ds = 0.16-0.55). In Study 1, participants' attitudes in the nonmoral condition were marginally de-moralized compared with those of participants in the control condition (d = -0.10). In Studies 2 and 3, participants' attitudes in the nonmoral condition were significantly de-moralized compared with those of participants in the control condition (ds = -0.15 to -0.20). Overall, moral messages moralized participants' attitudes, whereas nonmoral messages demoralized participants' attitudes.</p><p>In Study 3, we also tested whether the conditions similarly affected other dimensions of attitude strength (for full details, see Table <ref type="table">S5</ref> and Fig. <ref type="figure" target="#fig_3">S6</ref> in the Supplemental Material). Moral frames increased all other dimensions of attitude strength (ds = 0.32-0.55). However, nonmoral frames did not affect all other dimensions of attitude strength. They increased certainty (d = 0.20) and extremity (d = 0.44) but did not have a significant effect on importance and centrality. This is different from moral conviction, in which the nonmoral frame significantly decreased moral conviction, suggesting that moral conviction is affected differently by this framing and providing experimental evidence that moral conviction is a distinct dimension of attitude strength (cf. <ref type="bibr" target="#b30">Skitka et al., 2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Side Effect 2: effect of condition on willingness to compromise</head><p>We now turn to willingness to compromise, which was assessed only in Study 3 using two self-report measures and one behavioral measure. Each section below presents results for each variable. Results for all the variables are shown in Table <ref type="table" target="#tab_2">3</ref> and <ref type="table" target="#tab_2">Figure 3</ref>. For details regarding the association between moral conviction and willingness to compromise, see Table <ref type="table">S6</ref> and Figure <ref type="figure">S7</ref> in the Supplemental Material.  Self-reported willingness to compromise. To assess the effect of the condition on support for the uncompromising candidate and uncompromising manager, we regressed support for the uncompromising candidate or manager on dummy-coded condition (reference: moral condition). We used the moral condition as the reference group for these analyses because our hypothesis predicted a difference between the moral condition and the other two conditions. As predicted, we found that people were more likely to support the uncompromising candidate in the moral condition compared with both the control and nonmoral conditions (ds = -0.22 to -0.16). We found mixed results for the uncompromising manager. People were more likely to work with the uncompromising manager in the moral condition compared with the control condition but not compared with the nonmoral conditions (although the effect sizes were very similar: ds = -0.15 to -0.14).</p><p>To assess the effect of the condition on support for the compromising candidate or compromising manager, we regressed support for the compromising candidate or manager on dummy-coded conditions (reference: nonmoral condition). We used the nonmoral condition as the reference group for these analyses because our hypothesis predicted a difference between the nonmoral condition and the other two conditions. The results for the candidate were not in line with our predictions. We found that people did not differ in their support for the compromising candidate in the nonmoral condition compared with the control condition or the moral condition (ds = 0.07 to -0.11). We found mixed results for the compromising manager. People did not differ in their willingness to work with the compromising manager in the nonmoral condition compared with the control condition, but there was a significant difference in willingness between the nonmoral and moral conditions (ds = -0.04 to -0.25). In short, our hypotheses regarding willingness to work for the uncompromising candidate and manager were largely supported, but our hypotheses regarding willingness to work for the compromising candidate and manager received mixed support at best. Incentivized compromise game. Next, using an incentivized compromise game, we assessed whether there was an effect of condition on whether people were more willing to pick policies that represented a compromise of their position. To test this, we regressed the payoff for the opponent (indicating more compromise of the participant's position) on dummy-coded conditions (reference: control condition). As predicted, we found that people in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential mechanisms of moralization and de-moralization</head><p>Across the three studies, we found that moral frames and nonmoral frames were equally persuasive but that moral frames increased the strength of people's moral convictions and made them less willing to compromise, whereas nonmoral frames decreased the strength of people's moral convictions. This shows that moral frames can be effective persuasive tools and at the same time cause side effects. It is less clear why the moral frames have these effects. That is, what about the frames might cause the moralization and de-moralization effects we observed? In Studies 2 and 3, we explored whether emotional reactions and perceptions of risks and benefits are impacted by the experimental conditions and correlated with moralization. In Study 3, we additionally explored the impact of condition on finding the technology financially costly and on weighing costs and benefits. If these are candidates for mechanisms, they should be differentially affected by the two persuasive conditions. The factors that are higher in the moral condition should also be positively correlated with moral conviction, and the factors that are higher in the nonmoral condition should be negatively correlated with moral conviction (for Study 2, this is moral conviction at Time 2). We conducted separate regression analyses with each of the possible mechanism variables as the dependent variable. Condition was dummy coded (reference: control condition). The main results are shown in Figures <ref type="figure" target="#fig_1">4</ref>, <ref type="figure" target="#fig_2">5</ref>, and 6. (More details are available in Fig. <ref type="figure">S8</ref> and Table <ref type="table">S7</ref> in the Supplemental Material.) For the sake of brevity, we focus only on the results that provide some evidence that the variable is a potential mechanism. These variables were anger, disgust, and perceptions of financial cost. In both Study 2 and Study 3, participants reported significantly more anger (Study 2: β = 0.15, SE = 0.029, p ≤ .001, d = 0.32; Study 3: β = 0.17, SE = 0.036, p ≤ .001, d = 0.37) and disgust (Study 2: β = 0.12, SE = 0.029, p ≤ .001, d = 0.23; Study 3: β = 0.20, SE = 0.036, p ≤ .001, d = 0.42) in the moral condition than the control condition, but there were no differences between the nonmoral and control conditions. In both studies, disgust was positively correlated with moral conviction, whereas anger was correlated with moral conviction only in Study 2. This suggests that feelings of anger and disgust may help explain the differences in moralization between the moral-frame condition and the other two conditions. In Study 3, the extent to which participants found the technology financially costly was significantly higher in the nonmoral condition than in the control condition (β = 0.26, SE = 0.035, p ≤ .001, d = 0.55), but there were no differences between the moral and control conditions. This factor was also associated negatively with moral conviction. This suggests that perceptions of financial cost may help explain the differences in moralization between the nonmoral-frame condition and the other two conditions.</p><p>Notably, as detailed in the Supplemental Material (see Fig. <ref type="figure">S8</ref> and Table <ref type="table">S7</ref>), other potential mechanisms did differ by condition and were correlated with moral conviction. We do not think that they represent likely mechanisms because both the moral and nonmoral frames affected the measure in the same way (e.g., both increased perceived risks) or the measure was not correlated with moral conviction (e.g., fear was unassociated with moral conviction).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>We tested for side effects of moral framing and reframing strategies on people's moral convictions and willingness to compromise. We found that moral frames are persuasive and moralize people's attitudes, whereas nonmoral frames are persuasive and de-moralize people's attitudes. People who read moral frames are more likely to support uncompromising individuals and less willing to compromise themselves. We also found that anger and disgust potentially drive moralization and that considering how financially costly a technology is potentially drives de-moralization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theoretical and practical implications</head><p>We indeed found moralization and compromise side effects of moral framing and reframing strategies. Whether these side effects are an unexpected benefit or harm depends on the goals of the persuader. If the attitude change is considered as the morally correct attitude, these side effects may be beneficial. However, if the goal is to bridge divides, these side effects may be detrimental because they could entrench rather than bridge divides. For example, less willingness to compromise can delay policymakers from coming to a solution and cause a stalemate. Before we use these framing strategies to address delicate situations (e.g., the COVID-19 pandemic; <ref type="bibr" target="#b34">Van Bavel et al., 2020)</ref>, they should be tested in the specific context with careful attention paid to their side effects.</p><p>Our results confirm that moral frames are associated with moral emotions of anger and disgust, as shown previously (e.g., <ref type="bibr">Feinberg et al., 2019;</ref><ref type="bibr" target="#b39">Wisneski &amp; Skitka, 2017)</ref>. We additionally found that they are specifically associated with moral frames and not with nonmoral frames, which further supports their association with moralization.</p><p>Perceived Risks Perceived Benefits Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message Study 2 Study 3 2 4 6 Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message 2 4 6 Importantly, moralization is not the only possible outcome. We found a de-moralization effect that occurs when people read the nonmoral frames. Previous studies have examined differences between moral and pragmatic rhetoric, but either they did not find an effect <ref type="bibr" target="#b35">(Van Zant &amp; Moore, 2015)</ref> or it was unclear whether moralization or de-moralization occurs because there was no control condition <ref type="bibr" target="#b22">(Marietta, 2008)</ref>. In contrast, we directly examined de-moralization and found that nonmoral frames reduce moralization compared with a control condition. We also found initial evidence for why de-moralization occurs.</p><p>People consider the Anger Disgust Fear Feeling Creeped Out Gratefulness Study 2 Study 3 Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message 2 4 6 Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message Control Message Control Message Nonmoral Message Nonmoral Message Harm-or Fairness-Based Moral Message Harm-or Fairness-Based Moral Message 2 4 6 Weighing Costs and Benefits 2 4 6 Perceived Financial Cost technology more financially costly, specifically in the nonmoral frame, and this is negatively associated with moral conviction. This is in line with the findings of <ref type="bibr" target="#b2">Bastian et al. (2015)</ref>, who showed that monetary costs diminished the negative effect of moral conviction on the acceptance of mining. Nonmoral frames also increased certainty and extremity, even as they reduced the strength of moral convictions, providing further evidence that moral conviction is a unique dimension of attitude strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strengths and limitations</head><p>Our study had several strengths. First, the pretest/posttest design in Studies 1 and 2 measured change in people's moral convictions. Second, multiple measures of willingness to compromise, including a behavioral measure, more comprehensively assessed situations in which people do or do not compromise. Third, we compared moral and nonmoral frames with a neutral control condition, providing differential evidence for moralization and de-moralization and teasing out mechanisms specific to each of these processes.</p><p>There are, however, constraints on the generalizability of the findings. First, new big-data technologies may not be politicized in the same way as other issues that have been studied. Although the baseline measures for moral conviction (Ms = 4.65-5) show that people's attitudes about big-data technologies are moralized, people may not think of big-data issues as centrally or as often as other politicized issues, such as abortion rights, immigration, or the minimum wage. Thus, it is an open question whether our findings generalize only to issues with similar levels of politicization or whether they also generalize to more polarized and politicized issues. Regardless, it is worthwhile to test for side effects of framing and reframing strategies in any specific context before such strategies are used as a persuasion tool.</p><p>Although the effects related to de-moralization and compromise are small in magnitude, they are similar to effect sizes found in the modern persuasion literature (e.g., reducing prejudice; <ref type="bibr" target="#b5">Broockman &amp; Kalla, 2021;</ref><ref type="bibr" target="#b25">Paluck et al., 2021)</ref>. Effect sizes might be increased by using reinforcing persuasive messages at various time intervals with multiple exposures to persuasion. Future research could test this.</p><p>Finally, our study relied on U.S. participants recruited through Prolific. This was to maintain comparability with prior studies in moral framing and reframing <ref type="bibr" target="#b10">(Feinberg &amp; Willer, 2013;</ref><ref type="bibr" target="#b21">Luttrell et al., 2019)</ref>; however, testing in other contexts is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Moral frames are persuasive and moralize people's attitudes, whereas nonmoral frames are persuasive and de-moralize people's attitudes. Moral frames also reduce compromise. The use of moral frames as a persuasion tool should be considered cautiously and assessed for potential side effects; otherwise the goal of bridging moral divides with these tools may backfire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transparency</head><p>Action Editor: Andrew Luttrell Editor: Patricia J. Bauer</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Effect of condition on moral conviction for the technology at Time 2 in Studies 1 and 2 and effect of condition on moral conviction at Time 1 in Study 3. Colored dots represent observed data for each participant in each condition, and the accompanying distributions represent the density of the data. Black dots represent estimated means (controlling for Time 1 attitude support in Study 1 and Study 2). Error bars around estimated means denote 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Effect of condition on perceived risks (top row) and perceived benefits (bottom row) in Study 2 (left) and Study 3 (right). Colored dots represent observed data for each participant in each condition, and the accompanying distributions represent the density of the data. Black dots represent estimated means. Error bars around estimated means denote 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Effect of condition on each of five perceived emotions in Study 2 (left) and Study 3 (right). Colored dots represent observed data for each participant in each condition, and the accompanying distributions represent the density of the data. Black dots represent estimated means. Error bars around estimated means denote 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Effect of condition on the extent of weighing costs and benefits (left) and perceived financial cost (right) in Study 3. Colored dots represent observed data for each participant in each condition, and the accompanying distributions represent the density of the data. Black dots represent estimated means. Error bars around estimated means denote 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Design of Studies 1 to 3 and Demographic Statistics of Participants</figDesc><table><row><cell>Variable</cell><cell>Study 1</cell><cell>Study 2</cell><cell>Study 3</cell></row><row><cell>Number of time points</cell><cell>2</cell><cell>2</cell><cell>1</cell></row><row><cell>Technology</cell><cell>Crime-surveillance</cell><cell>Hiring</cell><cell>Hiring</cell></row><row><cell></cell><cell>technology</cell><cell>algorithm</cell><cell>algorithm</cell></row><row><cell>Number of experimental conditions</cell><cell>4</cell><cell>3</cell><cell>3</cell></row><row><cell>Measures</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Attitude support</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Moral conviction</cell><cell>Yes</cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Willingness to compromise</cell><cell></cell><cell></cell><cell>Yes</cell></row><row><cell>Compromise behavior</cell><cell></cell><cell></cell><cell>Yes</cell></row><row><cell>Perception of risks and benefits</cell><cell></cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Emotional reactions</cell><cell></cell><cell>Yes</cell><cell>Yes</cell></row><row><cell>Weighing costs and benefits</cell><cell></cell><cell></cell><cell>Yes</cell></row><row><cell>Time 1 sample size</cell><cell>2,229</cell><cell>1,654</cell><cell>1,015 a</cell></row><row><cell>Time 2 sample size</cell><cell>2,151</cell><cell>1,590</cell><cell></cell></row><row><cell>Platform</cell><cell>Prolific</cell><cell>Prolific</cell><cell>Prolific</cell></row><row><cell>Participant nation</cell><cell>United States</cell><cell>United States</cell><cell>United States</cell></row><row><cell>Women in sample (%)</cell><cell>49.40</cell><cell>43.70</cell><cell>48.90</cell></row><row><cell>Participant age (years)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>34.5</cell><cell>34.3</cell><cell>32.4</cell></row><row><cell>SD</cell><cell>12.8</cell><cell>11.6</cell><cell>11.5</cell></row><row><cell>Range</cell><cell>18-82</cell><cell>18-77</cell><cell>18-78</cell></row></table><note><p>a There was only one time point in Study 3.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Effect of Condition on Attitude Support and Moral Conviction in Studies 1 to 3 Fig. 1. Effect of condition on support for the technology at Time 2 in Studies 1 and 2 and effect of condition on support for the technology at Time 1 in Study 3. Colored dots represent observed data for each participant in each condition, and the accompanying distributions represent the density of the data. Black dots represent estimated means (controlling for Time 1 attitude support in Study 1 and Study 2). Error bars around estimated means denote 95% confidence intervals.</figDesc><table><row><cell></cell><cell></cell><cell>Study 1</cell><cell></cell><cell></cell><cell>Study 2</cell><cell></cell><cell></cell><cell>Study 3</cell><cell></cell></row><row><cell>Dependent variable and</cell><cell></cell><cell></cell><cell>Cohen's</cell><cell></cell><cell></cell><cell>Cohen's</cell><cell></cell><cell></cell><cell>Cohen's</cell></row><row><cell>predictor</cell><cell>β</cell><cell>p</cell><cell>d</cell><cell>β</cell><cell>p</cell><cell>d</cell><cell>β</cell><cell>p</cell><cell>d</cell></row><row><cell>Attitude support</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Attitude support at</cell><cell>0.66</cell><cell>&lt; .001</cell><cell></cell><cell>0.53</cell><cell>&lt; .001</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time 1</cell><cell>(0.019)</cell><cell></cell><cell></cell><cell>(0.021)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Moral condition</cell><cell>-0.19</cell><cell>&lt; .001</cell><cell>-0.44</cell><cell>-0.21</cell><cell>&lt; .001</cell><cell>-0.44</cell><cell>-0.37</cell><cell>&lt; .001</cell><cell>-0.78</cell></row><row><cell>(harm based)</cell><cell>(0.019)</cell><cell></cell><cell></cell><cell>(0.024)</cell><cell></cell><cell></cell><cell>(0.034)</cell><cell></cell><cell></cell></row><row><cell>Moral condition</cell><cell>-0.18</cell><cell>&lt; .001</cell><cell>-0.42</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(liberty based)</cell><cell>(0.019)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Nonmoral condition</cell><cell>-0.19</cell><cell>&lt; .001</cell><cell>-0.43</cell><cell>-0.22</cell><cell>&lt; .001</cell><cell>-0.46</cell><cell>-0.32</cell><cell>&lt; .001</cell><cell>-0.67</cell></row><row><cell></cell><cell>(0.019)</cell><cell></cell><cell></cell><cell>(0.024)</cell><cell></cell><cell></cell><cell>(0.034)</cell><cell></cell><cell></cell></row><row><cell>Moral conviction</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Moral conviction at</cell><cell>0.40</cell><cell>&lt; .001</cell><cell></cell><cell>0.42</cell><cell>&lt; .001</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Time 1</cell><cell>(0.024)</cell><cell></cell><cell></cell><cell>(0.023)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Moral condition</cell><cell>0.11</cell><cell>&lt; .001</cell><cell>0.24</cell><cell>0.10</cell><cell>&lt; .001</cell><cell>0.22</cell><cell>0.26</cell><cell>&lt; .001</cell><cell>0.55</cell></row><row><cell>(harm based)</cell><cell>(0.024)</cell><cell></cell><cell></cell><cell>(0.026)</cell><cell></cell><cell></cell><cell>(0.034)</cell><cell></cell><cell></cell></row><row><cell>Moral condition</cell><cell>0.07</cell><cell>.003</cell><cell>0.16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(liberty based)</cell><cell>(0.024)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Nonmoral condition</cell><cell>-0.04</cell><cell>.08</cell><cell>-0.10</cell><cell>-0.07</cell><cell>.007</cell><cell>-0.15</cell><cell>-0.10</cell><cell>.005</cell><cell>-0.20</cell></row><row><cell></cell><cell>(0.024)</cell><cell></cell><cell></cell><cell>(0.026)</cell><cell></cell><cell></cell><cell>(0.034)</cell><cell></cell><cell></cell></row></table><note><p>Note: Standard errors are given in parentheses. The reference group for the dummy-coded conditions is the control condition. In Studies 2 and 3, the moral condition included both harm-and fairness-based arguments, and there was no liberty-based moral condition. Attitude support refers to participants' attitude toward the technology in the study.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Effect of Condition and Moral Conviction on Willingness to Compromise in Study 3</figDesc><table><row><cell>Dependent variable and condition</cell><cell>β</cell><cell>p</cell><cell>Cohen's d</cell></row><row><cell>Support for uncompromising candidate</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(reference: moral condition)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Control condition</cell><cell>-0.10 (0.036)</cell><cell>.005</cell><cell>-0.22</cell></row><row><cell>Nonmoral condition</cell><cell>-0.07 (0.036)</cell><cell>.043</cell><cell>-0.16</cell></row><row><cell>Support for compromising candidate</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(reference: nonmoral condition)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Control condition</cell><cell>0.03 (0.036)</cell><cell>.384</cell><cell>0.07</cell></row><row><cell>Moral condition</cell><cell>-0.05 (0.036)</cell><cell>.138</cell><cell>-0.11</cell></row><row><cell>Willingness to work with uncompromising</cell><cell></cell><cell></cell><cell></cell></row><row><cell>manager (reference: moral condition)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Control condition</cell><cell>-0.07 (0.036)</cell><cell>.049</cell><cell>-0.15</cell></row><row><cell>Nonmoral condition</cell><cell>-0.06 (0.036)</cell><cell>.078</cell><cell>-0.14</cell></row><row><cell>Willingness to work with compromising</cell><cell></cell><cell></cell><cell></cell></row><row><cell>manager (reference: nonmoral condition)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Control condition</cell><cell>-0.02 (0.036)</cell><cell>.582</cell><cell>-0.04</cell></row><row><cell>Moral condition</cell><cell>-0.12 (0.036)</cell><cell>&lt; .001</cell><cell>-0.25</cell></row><row><cell>Willingness to compromise in the</cell><cell></cell><cell></cell><cell></cell></row><row><cell>incentivized compromise game</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(reference: control condition)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Moral condition</cell><cell>-0.08 (0.036)</cell><cell>.038</cell><cell>-0.16</cell></row><row><cell>Nonmoral condition</cell><cell>-0.03 (0.036)</cell><cell>.438</cell><cell>-0.06</cell></row></table><note><p>Note: Standard errors are given in parentheses.</p></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>the moral condition were less likely to compromise than people in the control condition (d = -0.16). However, there was no significant difference in compromise between people in the nonmoral and control conditions (d = -0.06). Not only did the moral frame increase people's self-reported willingness to support uncompromising candidates and managers, but this frame also increased the intransigence of people's decisions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) declared that there were no conflicts of interest with respect to the authorship or the publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices</head><p>All data, analysis code, and materials for Studies 1 to 3 have been made publicly available via OSF and can be accessed at <ref type="url" target="https://osf.io/3vfas/">https://osf.io/3vfas/</ref>. The design and analysis plans for the studies were preregistered-Study 1: <ref type="url" target="https://osf.io/sf2pq/">https://  osf.io/sf2pq/</ref>, Study 2: <ref type="url" target="https://osf.io/7rzx8/">https://osf.io/7rzx8/</ref>, Study 3: <ref type="url" target="https://osf.io/sqa9w/">https://osf.io/sqa9w/</ref>. This article has received the badges for Open Data, Open Materials, and Preregistration. More information about the Open Practices badges can be found at <ref type="url" target="http://www.psychologicalscience.org/publications/badges">http://www.psychologicalscience.org/publications/  badges</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ORCID iDs</head><p>Rabia I. Kodapanakkal <ref type="url" target="https://orcid.org/0000-0002-3113-332X">https://orcid.org/0000-0002- 3113-332X</ref> Mark J. Brandt <ref type="url" target="https://orcid.org/0000-0002-7185-7031">https://orcid.org/0000-0002-7185-7031</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Additional supporting information can be found at <ref type="url" target="http://journals.sagepub.com/doi/suppl/10.1177/09567976211040803">http://  journals.sagepub.com/doi/suppl/10.1177/09567976211040803</ref> Note 1. Our preregistered hypothesis (<ref type="url" target="https://osf.io/sf2pq/">https://osf.io/sf2pq/</ref>) was that people with attitudes based in harm or liberty concerns would be persuaded by corresponding moral frames of harm and liberty. However, we found that all messages were persuasive and did not find evidence for a moral-reframing effect. For full details, see the Supplemental Material. The primary analyses we report in Study 1 should be treated as exploratory.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Finding the right value: Framing effects on domain experts</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Clawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Gramig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Raymond</surname></persName>
		</author>
		<idno type="DOI">10.1111/pops.12339</idno>
		<ptr target="https://doi.org/10.1111/pops.12339" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="278" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Opposing torture: Moral conviction and resistance to majority influence</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Aramovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Lytle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<idno type="DOI">10.1080/15534510.2011.640199</idno>
		<ptr target="https://doi.org/10.1080/15534510.2011.640199" />
	</analytic>
	<monogr>
		<title level="j">Social Influence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="34" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The interaction of economic rewards and moral convictions in predicting attitudes toward resource use</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moffat</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0134863</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0134863" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">134863</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">DeclareDesign: Declare and diagnose research designs (Version 0.30</title>
		<author>
			<persName><forename type="first">G</forename><surname>Blair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Coppock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fultz</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/web/packages/DeclareDesign/index.html" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Moralization and the 2012 U.S. presidential election campaign</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wisneski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<idno type="DOI">10.5964/jspp.v3i2.434</idno>
		<ptr target="https://doi.org/10.5964/jspp.v3i2.434" />
	</analytic>
	<monogr>
		<title level="j">Journal of Social and Political Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="237" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">When and why are campaigns&apos; persuasive effects small? Evidence from the 2020 US presidential election</title>
		<author>
			<persName><forename type="first">D</forename><surname>Broockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kalla</surname></persName>
		</author>
		<idno type="DOI">10.31219/osf.io/m7326</idno>
		<ptr target="https://doi.org/10.31219/osf.io/m7326" />
	</analytic>
	<monogr>
		<title level="j">OSF Preprints</title>
		<imprint>
			<date type="published" when="2021-09-07">2021, September 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How emotional frames moralize and polarize political attitudes</title>
		<author>
			<persName><forename type="first">S</forename><surname>Clifford</surname></persName>
		</author>
		<idno type="DOI">10.1111/pops.12507</idno>
		<ptr target="https://doi.org/10.1111/pops.12507" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="91" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The nature and value of the moral right to privacy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Corlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Affairs Quarterly</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="329" to="350" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Moral obstinacy in political negotiations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Delton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Descioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<idno type="DOI">10.1111/pops.12612</idno>
		<ptr target="https://doi.org/10.1111/pops.12612" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="20" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Understanding the process of moralization: How eating meat becomes a moral issue</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kovacheff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Teper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Inbar</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspa0000149</idno>
		<ptr target="https://doi.org/10.1037/pspa0000149" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="72" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The moral roots of environmental attitudes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willer</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797612449177</idno>
		<ptr target="https://doi.org/10.1177/0956797612449177" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="62" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From gulf to bridge: When do moral arguments facilitate political influence?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willer</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167215607842</idno>
		<ptr target="https://doi.org/10.1177/0146167215607842" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1665" to="1681" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Moral reframing: A technique for effective and persuasive communication across political divides</title>
		<author>
			<persName><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willer</surname></persName>
		</author>
		<idno type="DOI">10.1111/spc3.12501</idno>
		<ptr target="https://doi.org/10.1111/spc3.12501" />
	</analytic>
	<monogr>
		<title level="j">Social and Personality Psychology Compass</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Article e12501</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The moral roots of partisan division: How moral conviction heightens affective polarization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Garrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bankert</surname></persName>
		</author>
		<idno type="DOI">10.1017/S000712341700059X</idno>
		<ptr target="https://doi.org/10.1017/S000712341700059X" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="621" to="640" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The psychology of meta-ethics: Exploring objectivism</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Darley</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2007.06.007</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2007.06.007" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1339" to="1366" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Moral framing and charitable donation: Integrating exploratory social media analyses and confirmatory experimentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Boghrati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<idno type="DOI">10.1525/collabra.129</idno>
		<ptr target="https://doi.org/10.1525/collabra.129" />
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>Article 9</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Getting liberals and conservatives to go green: Political ideology and congruent appeals</title>
		<author>
			<persName><forename type="first">B</forename><surname>Kidwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Hardesty</surname></persName>
		</author>
		<idno type="DOI">10.1086/670610</idno>
		<ptr target="https://doi.org/10.1086/670610" />
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="350" to="367" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discrimination in the age of algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
		<idno type="DOI">10.1093/jla/laz001</idno>
		<ptr target="https://doi.org/10.1093/jla/laz001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Legal Analysis</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="113" to="174" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-interest and data protection drive the adoption and moral acceptability of big data technologies: A conjoint analysis approach</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Kodapanakkal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kogler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Beest</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2020.106303</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2020.106303" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">106303</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Moral relevance varies due to inter-individual and intra-individual differences across big data technology domains</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Kodapanakkal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kogler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Van Beest</surname></persName>
		</author>
		<idno type="DOI">10.1002/ejsp.2814</idno>
		<ptr target="https://doi.org/10.1002/ejsp.2814" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Social Psychology. Advance online</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Making it moral: Merely labeling an attitude as moral increases its strength</title>
		<author>
			<persName><forename type="first">A</forename><surname>Luttrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Briñol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2016.04.003</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2016.04.003" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="82" to="93" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Challenging moral attitudes with moral messages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Luttrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Philipp-Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Petty</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797619854706</idno>
		<ptr target="https://doi.org/10.1177/0956797619854706" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1136" to="1150" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">From my cold, dead hands: Democratic consequences of sacred rhetoric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Marietta</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0022381608080742</idno>
		<ptr target="https://doi.org/10.1017/S0022381608080742" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Politics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="767" to="779" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The motivating role of perceived right violation and efficacy beliefs in identification with the Italian water movement</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mazzoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zomeren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cicognani</surname></persName>
		</author>
		<idno type="DOI">10.1111/pops.12101</idno>
		<ptr target="https://doi.org/10.1111/pops.12101" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="315" to="330" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring the psychological underpinnings of the moral mandate effect: Motivated reasoning, group differentiation, or anger?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.90.4.629</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.90.4.629" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="643" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Prejudice reduction: Progress and challenges</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Paluck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Porat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="533" to="560" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The process of moralization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rozin</surname></persName>
		</author>
		<idno type="DOI">10.1111/1467-9280.00139</idno>
		<ptr target="https://doi.org/10.1111/1467-9280.00139" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="218" to="221" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">No compromise: Political consequences of moralized attitudes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<idno type="DOI">10.1111/ajps.12248</idno>
		<ptr target="https://doi.org/10.1111/ajps.12248" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="409" to="423" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The theory of dyadic morality: Reinventing moral judgment by redefining harm</title>
		<author>
			<persName><forename type="first">C</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1177/1088868317698288</idno>
		<ptr target="https://doi.org/10.1177/1088868317698288" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="70" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Moral conviction and political engagement</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Bauman</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9221.2007.00611.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9221.2007.00611.x" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="54" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Moral conviction: Another contributor to attitude strength or something more</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Bauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Sargis</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.88.6.895</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.88.6.895" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="895" to="917" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The psychology of moral conviction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wisneski</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-063020-030612</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-063020-030612" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="347" to="366" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The social and political implications of moral conviction</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Morgan</surname></persName>
		</author>
		<idno type="DOI">10.1111/pops.12166</idno>
		<ptr target="https://doi.org/10.1111/pops.12166" />
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">tidystats: Save output of statistical tests (Version 0.5)</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W A</forename><surname>Sleegers</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4041859</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4041859" />
	</analytic>
	<monogr>
		<title level="j">Computer software</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Using social and behavioural science to support COVID-19 pandemic response</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Bavel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Boggio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Capraro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cichocka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cikara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Crum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Druckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Drury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dube</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ellemers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Haslam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jetten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Willer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41562-020-0884-z</idno>
		<ptr target="https://doi.org/10.1038/s41562-020-0884-z" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="460" to="471" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Leaders&apos; use of moral justifications increases policy support</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">B</forename><surname>Van Zant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797615572909</idno>
		<ptr target="https://doi.org/10.1177/0956797615572909" />
	</analytic>
	<monogr>
		<title level="j">Psycho logical Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="934" to="943" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Can moral convictions motivate the advantaged to challenge social inequality? Extending the social identity model of collective action</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Zomeren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Postmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Spears</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bettache</surname></persName>
		</author>
		<idno type="DOI">10.1177/1368430210395637</idno>
		<ptr target="https://doi.org/10.1177/1368430210395637" />
	</analytic>
	<monogr>
		<title level="j">Group Processes &amp; Intergroup Relations</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="735" to="753" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Morally reframed arguments can affect support for political candidates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Voelkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Feinberg</surname></persName>
		</author>
		<idno type="DOI">10.1177/1948550617729408</idno>
		<ptr target="https://doi.org/10.1177/1948550617729408" />
	</analytic>
	<monogr>
		<title level="j">Social Psychological and Personality Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="917" to="924" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Resolving the progressive paradox: The effects of moral reframing on support for economically progressive candidates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Voelkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mernyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willer</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/mtfjn</idno>
		<ptr target="https://doi.org/10.31234/osf.io/mtfjn" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">PsyArXiv</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Moralization through moral shock: Exploring emotional antecedents to moral conviction</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Wisneski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Skitka</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167216676479</idno>
		<ptr target="https://doi.org/10.1177/0146167216676479" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="150" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
